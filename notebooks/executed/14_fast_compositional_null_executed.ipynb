{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb655398",
   "metadata": {
    "papermill": {
     "duration": 0.008858,
     "end_time": "2025-10-08T07:15:42.122778",
     "exception": false,
     "start_time": "2025-10-08T07:15:42.113920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fast Compositional Null Calculator\n",
    "\n",
    "This notebook builds and validates a fast compositional null generator using ML model predictions.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Create a fast method to compute metapath null probabilities:\n",
    "- **Use ML predictions** instead of analytical formula\n",
    "- **Compositional calculation**: P(path) = Σ P(edge1) × P(edge2) × ...\n",
    "- **Validate** against true null from permutations\n",
    "- **Benchmark** speed and accuracy\n",
    "\n",
    "## Key Insight\n",
    "\n",
    "**Current problem**: Analytical formula fails (r=0.065)  \n",
    "**Solution**: Replace analytical with ML predictions (r=0.83), keep compositional structure\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Load null models from notebook 13\n",
    "2. Create prediction lookup tables\n",
    "3. Implement compositional calculator\n",
    "4. Validate on test metapath (CbGpPW)\n",
    "5. Error analysis by degree\n",
    "6. Performance benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26dfb55f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T07:15:42.137880Z",
     "iopub.status.busy": "2025-10-08T07:15:42.137388Z",
     "iopub.status.idle": "2025-10-08T07:15:42.146534Z",
     "shell.execute_reply": "2025-10-08T07:15:42.145941Z"
    },
    "papermill": {
     "duration": 0.017614,
     "end_time": "2025-10-08T07:15:42.147518",
     "exception": false,
     "start_time": "2025-10-08T07:15:42.129904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Papermill parameters\n",
    "test_metapath = \"CbGpPW\"  # Test metapath for validation\n",
    "test_edge_types = [\"CbG\", \"GpPW\"]  # Edge types in test metapath\n",
    "validation_perm_range = (21, 31)  # Perms 21-30 for validation\n",
    "model_type = \"rf\"  # 'rf' or 'poly' or 'ensemble'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92a312d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T07:15:42.162617Z",
     "iopub.status.busy": "2025-10-08T07:15:42.162286Z",
     "iopub.status.idle": "2025-10-08T07:15:44.125514Z",
     "shell.execute_reply": "2025-10-08T07:15:44.124871Z"
    },
    "papermill": {
     "duration": 1.972671,
     "end_time": "2025-10-08T07:15:44.127165",
     "exception": false,
     "start_time": "2025-10-08T07:15:42.154494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository directory: /projects/lgillenwater@xsede.org/repositories/Context-Aware-Path-Probability\n",
      "Null models directory: /projects/lgillenwater@xsede.org/repositories/Context-Aware-Path-Probability/results/null_models\n",
      "Results will be saved to: /projects/lgillenwater@xsede.org/repositories/Context-Aware-Path-Probability/results/compositional_null\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import pearsonr, ks_2samp\n",
    "import joblib\n",
    "import time\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "repo_dir = Path.cwd()\n",
    "data_dir = repo_dir / 'data'\n",
    "null_models_dir = repo_dir / 'results' / 'null_models'\n",
    "results_dir = repo_dir / 'results' / 'compositional_null'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Repository directory: {repo_dir}\")\n",
    "print(f\"Null models directory: {null_models_dir}\")\n",
    "print(f\"Results will be saved to: {results_dir}\")\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a3c0b2",
   "metadata": {
    "papermill": {
     "duration": 0.006085,
     "end_time": "2025-10-08T07:15:44.141020",
     "exception": false,
     "start_time": "2025-10-08T07:15:44.134935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Load Null Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a8cb9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T07:15:44.153962Z",
     "iopub.status.busy": "2025-10-08T07:15:44.153626Z",
     "iopub.status.idle": "2025-10-08T07:15:44.531378Z",
     "shell.execute_reply": "2025-10-08T07:15:44.530801Z"
    },
    "papermill": {
     "duration": 0.38531,
     "end_time": "2025-10-08T07:15:44.532458",
     "exception": false,
     "start_time": "2025-10-08T07:15:44.147148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading null models for metapath CbGpPW...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CbG: ['rf']\n",
      "  GpPW: ['rf']\n",
      "\n",
      "✓ Loaded models for 2 edge types\n"
     ]
    }
   ],
   "source": [
    "def load_null_model(edge_type, model_type='rf'):\n",
    "    \"\"\"\n",
    "    Load trained null model for edge type.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    edge_type : str\n",
    "        Edge type (e.g., 'CbG')\n",
    "    model_type : str\n",
    "        'rf' for Random Forest, 'poly' for Polynomial LogReg, 'ensemble' for both\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with 'rf' and/or 'poly' keys containing models\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    if model_type in ['rf', 'ensemble']:\n",
    "        rf_file = null_models_dir / f'{edge_type}_rf_null.pkl'\n",
    "        if rf_file.exists():\n",
    "            models['rf'] = joblib.load(rf_file)\n",
    "    \n",
    "    if model_type in ['poly', 'ensemble']:\n",
    "        poly_file = null_models_dir / f'{edge_type}_poly_null.pkl'\n",
    "        poly_features_file = null_models_dir / f'{edge_type}_poly_features.pkl'\n",
    "        if poly_file.exists() and poly_features_file.exists():\n",
    "            models['poly'] = joblib.load(poly_file)\n",
    "            models['poly_features'] = joblib.load(poly_features_file)\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Test loading models for test metapath\n",
    "print(f\"Loading null models for metapath {test_metapath}...\")\n",
    "null_models = {}\n",
    "\n",
    "for edge_type in test_edge_types:\n",
    "    models = load_null_model(edge_type, model_type)\n",
    "    null_models[edge_type] = models\n",
    "    print(f\"  {edge_type}: {list(models.keys())}\")\n",
    "\n",
    "print(f\"\\n✓ Loaded models for {len(null_models)} edge types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c9442",
   "metadata": {
    "papermill": {
     "duration": 0.006594,
     "end_time": "2025-10-08T07:15:44.546600",
     "exception": false,
     "start_time": "2025-10-08T07:15:44.540006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Get Degree Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680c4b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T07:15:44.560762Z",
     "iopub.status.busy": "2025-10-08T07:15:44.560363Z",
     "iopub.status.idle": "2025-10-08T07:15:44.649727Z",
     "shell.execute_reply": "2025-10-08T07:15:44.649218Z"
    },
    "papermill": {
     "duration": 0.097188,
     "end_time": "2025-10-08T07:15:44.650628",
     "exception": false,
     "start_time": "2025-10-08T07:15:44.553440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing degree distributions for intermediate nodes...\n",
      "  Gene degrees: 132 unique degrees\n",
      "  Degree range: 1-516\n",
      "  Sample frequencies: {1: 0.17547806524184478, 6: 0.06092988376452944, 5: 0.07845894263217097, 3: 0.08361454818147732, 12: 0.017622797150356206}\n"
     ]
    }
   ],
   "source": [
    "def get_degree_distribution(node_type, edge_types_in_metapath, perm_id=0):\n",
    "    \"\"\"\n",
    "    Get degree distribution for intermediate nodes in metapath.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    node_type : str\n",
    "        Node type (e.g., 'Gene', 'Pathway')\n",
    "    edge_types_in_metapath : list\n",
    "        Edge types that connect to this node type\n",
    "    perm_id : int\n",
    "        Permutation ID (0 for Hetionet)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: {degree: frequency}\n",
    "    \"\"\"\n",
    "    # Map edge types to node indices\n",
    "    # For CbGpPW: Gene is intermediate, connects via CbG (target) and GpPW (source)\n",
    "    \n",
    "    degrees = []\n",
    "    \n",
    "    for edge_type in edge_types_in_metapath:\n",
    "        edge_file = data_dir / 'permutations' / f'{perm_id:03d}.hetmat' / 'edges' / f'{edge_type}.sparse.npz'\n",
    "        \n",
    "        if edge_file.exists():\n",
    "            matrix = sp.load_npz(str(edge_file))\n",
    "            \n",
    "            # Determine if node type is source or target in this edge type\n",
    "            # For simplicity, we'll use total degree (sum of in and out)\n",
    "            if 'G' in edge_type:  # Gene-related edges\n",
    "                if edge_type.endswith('G'):  # Gene is target\n",
    "                    node_degrees = np.array(matrix.sum(axis=0)).flatten()\n",
    "                else:  # Gene is source\n",
    "                    node_degrees = np.array(matrix.sum(axis=1)).flatten()\n",
    "                \n",
    "                degrees.extend(node_degrees[node_degrees > 0].tolist())\n",
    "    \n",
    "    # Count degree frequencies\n",
    "    degree_counts = Counter(degrees)\n",
    "    total = sum(degree_counts.values())\n",
    "    degree_freq = {deg: count/total for deg, count in degree_counts.items()}\n",
    "    \n",
    "    return degree_freq\n",
    "\n",
    "# Get gene degree distribution for CbGpPW metapath\n",
    "print(\"Computing degree distributions for intermediate nodes...\")\n",
    "gene_degree_freq = get_degree_distribution('Gene', test_edge_types, perm_id=0)\n",
    "print(f\"  Gene degrees: {len(gene_degree_freq)} unique degrees\")\n",
    "print(f\"  Degree range: {min(gene_degree_freq.keys())}-{max(gene_degree_freq.keys())}\")\n",
    "print(f\"  Sample frequencies: {dict(list(gene_degree_freq.items())[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8643b",
   "metadata": {
    "papermill": {
     "duration": 0.00648,
     "end_time": "2025-10-08T07:15:44.664617",
     "exception": false,
     "start_time": "2025-10-08T07:15:44.658137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Fast Compositional Null Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e597f994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T07:15:44.678577Z",
     "iopub.status.busy": "2025-10-08T07:15:44.678232Z",
     "iopub.status.idle": "2025-10-08T07:15:44.688214Z",
     "shell.execute_reply": "2025-10-08T07:15:44.687614Z"
    },
    "papermill": {
     "duration": 0.017819,
     "end_time": "2025-10-08T07:15:44.689056",
     "exception": false,
     "start_time": "2025-10-08T07:15:44.671237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compositional null calculator ready!\n"
     ]
    }
   ],
   "source": [
    "def predict_edge_probability(source_deg, target_deg, models, model_type='rf'):\n",
    "    \"\"\"\n",
    "    Predict edge probability using null model.\n",
    "    \"\"\"\n",
    "    if model_type == 'rf' and 'rf' in models:\n",
    "        pred = models['rf'].predict([[source_deg, target_deg]])[0]\n",
    "    elif model_type == 'poly' and 'poly' in models:\n",
    "        X = models['poly_features'].transform([[source_deg, target_deg]])\n",
    "        pred = models['poly'].predict(X)[0]\n",
    "    elif model_type == 'ensemble' and 'rf' in models and 'poly' in models:\n",
    "        pred_rf = models['rf'].predict([[source_deg, target_deg]])[0]\n",
    "        X = models['poly_features'].transform([[source_deg, target_deg]])\n",
    "        pred_poly = models['poly'].predict(X)[0]\n",
    "        pred = 0.5 * pred_rf + 0.5 * pred_poly\n",
    "    else:\n",
    "        pred = 0.0\n",
    "    \n",
    "    return np.clip(pred, 0, 1)\n",
    "\n",
    "def compute_metapath_null_2edge(source_degrees, target_degrees, \n",
    "                                edge1_models, edge2_models, \n",
    "                                intermediate_degree_freq,\n",
    "                                model_type='rf'):\n",
    "    \"\"\"\n",
    "    Compute null probability for 2-edge metapath (e.g., C-G-P).\n",
    "    \n",
    "    P_null(C→P) = Σ_g P(C→g) × P(g→P) × freq(g)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    source_degrees : array\n",
    "        Source node degrees (e.g., compound degrees)\n",
    "    target_degrees : array\n",
    "        Target node degrees (e.g., pathway degrees)\n",
    "    edge1_models : dict\n",
    "        Null models for first edge type\n",
    "    edge2_models : dict\n",
    "        Null models for second edge type\n",
    "    intermediate_degree_freq : dict\n",
    "        {degree: frequency} for intermediate nodes\n",
    "    model_type : str\n",
    "        'rf', 'poly', or 'ensemble'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    array of null probabilities\n",
    "    \"\"\"\n",
    "    null_probs = []\n",
    "    \n",
    "    for source_deg, target_deg in zip(source_degrees, target_degrees):\n",
    "        total_prob = 0.0\n",
    "        \n",
    "        # Sum over all intermediate node degrees\n",
    "        for inter_deg, freq in intermediate_degree_freq.items():\n",
    "            # P(source → intermediate)\n",
    "            p1 = predict_edge_probability(source_deg, inter_deg, edge1_models, model_type)\n",
    "            \n",
    "            # P(intermediate → target)\n",
    "            p2 = predict_edge_probability(inter_deg, target_deg, edge2_models, model_type)\n",
    "            \n",
    "            # Compositional multiplication weighted by intermediate degree frequency\n",
    "            total_prob += p1 * p2 * freq\n",
    "        \n",
    "        null_probs.append(total_prob)\n",
    "    \n",
    "    return np.array(null_probs)\n",
    "\n",
    "print(\"Compositional null calculator ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26031e4",
   "metadata": {
    "papermill": {
     "duration": 0.007792,
     "end_time": "2025-10-08T07:15:44.704691",
     "exception": false,
     "start_time": "2025-10-08T07:15:44.696899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Extract True Null from Validation Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a47a66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T07:15:44.719953Z",
     "iopub.status.busy": "2025-10-08T07:15:44.719512Z",
     "iopub.status.idle": "2025-10-08T07:16:03.999371Z",
     "shell.execute_reply": "2025-10-08T07:16:03.998841Z"
    },
    "papermill": {
     "duration": 19.288955,
     "end_time": "2025-10-08T07:16:04.000697",
     "exception": false,
     "start_time": "2025-10-08T07:15:44.711742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting true null from permutations 21-30...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracted 684757 metapath pairs\n",
      "  Source degree range: 1-132\n",
      "  Target degree range: 2-1956\n",
      "  Mean null probability: 1.460372e-06\n"
     ]
    }
   ],
   "source": [
    "def extract_metapath_frequencies(metapath_edges, perm_id):\n",
    "    \"\"\"\n",
    "    Extract observed metapath frequencies from a permutation.\n",
    "    \n",
    "    For 2-edge metapath C-G-P:\n",
    "    - Load C→G and G→P edge matrices\n",
    "    - Compute metapath matrix: C-G-P = (C→G) @ (G→P)\n",
    "    - Return frequencies for each (compound, pathway) pair\n",
    "    \"\"\"\n",
    "    edge1_type, edge2_type = metapath_edges\n",
    "    \n",
    "    # Load edge matrices\n",
    "    edge1_file = data_dir / 'permutations' / f'{perm_id:03d}.hetmat' / 'edges' / f'{edge1_type}.sparse.npz'\n",
    "    edge2_file = data_dir / 'permutations' / f'{perm_id:03d}.hetmat' / 'edges' / f'{edge2_type}.sparse.npz'\n",
    "    \n",
    "    if not edge1_file.exists() or not edge2_file.exists():\n",
    "        return None\n",
    "    \n",
    "    matrix1 = sp.load_npz(str(edge1_file))  # C × G\n",
    "    matrix2 = sp.load_npz(str(edge2_file))  # G × P\n",
    "    \n",
    "    # Compute metapath matrix: C × P\n",
    "    metapath_matrix = matrix1 @ matrix2\n",
    "    \n",
    "    # Get degrees\n",
    "    source_degrees = np.array(matrix1.sum(axis=1)).flatten()  # Compound degrees\n",
    "    target_degrees = np.array(matrix2.sum(axis=0)).flatten()  # Pathway degrees\n",
    "    \n",
    "    # Extract metapath frequencies\n",
    "    data = []\n",
    "    for i, j in zip(*metapath_matrix.nonzero()):\n",
    "        data.append({\n",
    "            'source_idx': i,\n",
    "            'target_idx': j,\n",
    "            'source_degree': int(source_degrees[i]),\n",
    "            'target_degree': int(target_degrees[j]),\n",
    "            'metapath_count': int(metapath_matrix[i, j]),\n",
    "            'perm_id': perm_id\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Extract true null from validation permutations\n",
    "print(f\"Extracting true null from permutations {validation_perm_range[0]}-{validation_perm_range[1]-1}...\")\n",
    "all_true_null = []\n",
    "\n",
    "for perm_id in range(validation_perm_range[0], validation_perm_range[1]):\n",
    "    df = extract_metapath_frequencies(test_edge_types, perm_id)\n",
    "    if df is not None:\n",
    "        all_true_null.append(df)\n",
    "\n",
    "true_null_df = pd.concat(all_true_null, ignore_index=True)\n",
    "\n",
    "# Aggregate across permutations\n",
    "true_null_agg = true_null_df.groupby(['source_idx', 'target_idx', 'source_degree', 'target_degree']).agg({\n",
    "    'metapath_count': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Normalize to probabilities\n",
    "total_paths = true_null_agg['metapath_count'].sum()\n",
    "true_null_agg['true_null_prob'] = true_null_agg['metapath_count'] / total_paths\n",
    "\n",
    "print(f\"  Extracted {len(true_null_agg)} metapath pairs\")\n",
    "print(f\"  Source degree range: {true_null_agg['source_degree'].min()}-{true_null_agg['source_degree'].max()}\")\n",
    "print(f\"  Target degree range: {true_null_agg['target_degree'].min()}-{true_null_agg['target_degree'].max()}\")\n",
    "print(f\"  Mean null probability: {true_null_agg['true_null_prob'].mean():.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d208a488",
   "metadata": {
    "papermill": {
     "duration": 0.007069,
     "end_time": "2025-10-08T07:16:04.014757",
     "exception": false,
     "start_time": "2025-10-08T07:16:04.007688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Compute ML-Compositional Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06300fa5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-10-08T07:16:04.021717",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Computing ML-compositional null using {model_type} model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Compute null for each (source, target) pair\n",
    "ml_null_probs = compute_metapath_null_2edge(\n",
    "    true_null_agg['source_degree'].values,\n",
    "    true_null_agg['target_degree'].values,\n",
    "    null_models[test_edge_types[0]],\n",
    "    null_models[test_edge_types[1]],\n",
    "    gene_degree_freq,\n",
    "    model_type=model_type\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "true_null_agg['ml_null_prob'] = ml_null_probs\n",
    "\n",
    "print(f\"  ✓ Computed {len(ml_null_probs)} null probabilities\")\n",
    "print(f\"  Computation time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"  Speed: {len(ml_null_probs)/elapsed_time:.0f} pairs/second\")\n",
    "print(f\"  Mean ML-null probability: {ml_null_probs.mean():.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e0b65",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Validate Against True Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25255ae2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove any zero or invalid values\n",
    "valid_mask = (true_null_agg['true_null_prob'] > 0) & (true_null_agg['ml_null_prob'] > 0)\n",
    "valid_data = true_null_agg[valid_mask].copy()\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  Valid pairs: {len(valid_data)} / {len(true_null_agg)}\")\n",
    "\n",
    "# Correlation\n",
    "corr, p_val = pearsonr(valid_data['true_null_prob'], valid_data['ml_null_prob'])\n",
    "print(f\"  Pearson correlation: r = {corr:.4f} (p = {p_val:.2e})\")\n",
    "\n",
    "# MAE and RMSE\n",
    "mae = np.abs(valid_data['true_null_prob'] - valid_data['ml_null_prob']).mean()\n",
    "rmse = np.sqrt(((valid_data['true_null_prob'] - valid_data['ml_null_prob'])**2).mean())\n",
    "print(f\"  MAE: {mae:.6e}\")\n",
    "print(f\"  RMSE: {rmse:.6e}\")\n",
    "\n",
    "# R²\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(valid_data['true_null_prob'], valid_data['ml_null_prob'])\n",
    "print(f\"  R²: {r2:.4f}\")\n",
    "\n",
    "# KS test\n",
    "ks_stat, ks_p = ks_2samp(valid_data['true_null_prob'], valid_data['ml_null_prob'])\n",
    "print(f\"  KS test: D = {ks_stat:.4f} (p = {ks_p:.2e})\")\n",
    "\n",
    "# Success criteria\n",
    "print(f\"\\nSuccess Criteria:\")\n",
    "print(f\"  Correlation > 0.75: {'✓' if corr > 0.75 else '✗'} ({corr:.4f})\")\n",
    "print(f\"  RMSE < 0.20: {'✓' if rmse < 0.20 else '✗'} ({rmse:.4f})\")\n",
    "print(f\"  R² > 0.50: {'✓' if r2 > 0.50 else '✗'} ({r2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a47b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Error Analysis by Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2948c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_errors_by_degree(predictions, actuals, source_degrees, target_degrees):\n",
    "    \"\"\"Analyze prediction errors stratified by degree bins.\"\"\"\n",
    "    degree_bins = [0, 1, 2, 5, 10, 20, 50, 100, 500, np.inf]\n",
    "    degree_labels = ['0', '1', '2-4', '5-9', '10-19', '20-49', '50-99', '100-499', '500+']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    source_bins = pd.cut(source_degrees, bins=degree_bins, labels=degree_labels)\n",
    "    target_bins = pd.cut(target_degrees, bins=degree_bins, labels=degree_labels)\n",
    "    \n",
    "    for bin_label in degree_labels:\n",
    "        mask = source_bins == bin_label\n",
    "        if mask.sum() >= 10:\n",
    "            results.append({\n",
    "                'stratification': 'source_degree',\n",
    "                'bin': bin_label,\n",
    "                'n_samples': int(mask.sum()),\n",
    "                'mean_prediction': float(predictions[mask].mean()),\n",
    "                'mean_actual': float(actuals[mask].mean()),\n",
    "                'mae': float(np.abs(predictions[mask] - actuals[mask]).mean()),\n",
    "                'rmse': float(np.sqrt(((predictions[mask] - actuals[mask])**2).mean())),\n",
    "                'correlation': float(np.corrcoef(predictions[mask], actuals[mask])[0,1]) if mask.sum() > 1 else np.nan\n",
    "            })\n",
    "    \n",
    "    for bin_label in degree_labels:\n",
    "        mask = target_bins == bin_label\n",
    "        if mask.sum() >= 10:\n",
    "            results.append({\n",
    "                'stratification': 'target_degree',\n",
    "                'bin': bin_label,\n",
    "                'n_samples': int(mask.sum()),\n",
    "                'mean_prediction': float(predictions[mask].mean()),\n",
    "                'mean_actual': float(actuals[mask].mean()),\n",
    "                'mae': float(np.abs(predictions[mask] - actuals[mask]).mean()),\n",
    "                'rmse': float(np.sqrt(((predictions[mask] - actuals[mask])**2).mean())),\n",
    "                'correlation': float(np.corrcoef(predictions[mask], actuals[mask])[0,1]) if mask.sum() > 1 else np.nan\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "error_analysis_df = analyze_errors_by_degree(\n",
    "    valid_data['ml_null_prob'].values,\n",
    "    valid_data['true_null_prob'].values,\n",
    "    valid_data['source_degree'].values,\n",
    "    valid_data['target_degree'].values\n",
    ")\n",
    "\n",
    "print(\"\\nError Analysis by Degree:\")\n",
    "print(\"\\nSource Degree:\")\n",
    "source_errors = error_analysis_df[error_analysis_df['stratification'] == 'source_degree']\n",
    "print(source_errors[['bin', 'n_samples', 'correlation', 'mae', 'rmse']].to_string(index=False))\n",
    "\n",
    "print(\"\\nTarget Degree:\")\n",
    "target_errors = error_analysis_df[error_analysis_df['stratification'] == 'target_degree']\n",
    "print(target_errors[['bin', 'n_samples', 'correlation', 'mae', 'rmse']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4547852",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3d567",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. True null vs ML null scatter\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(valid_data['true_null_prob'], valid_data['ml_null_prob'], alpha=0.5, s=20)\n",
    "ax.plot([valid_data['true_null_prob'].min(), valid_data['true_null_prob'].max()],\n",
    "        [valid_data['true_null_prob'].min(), valid_data['true_null_prob'].max()],\n",
    "        'r--', alpha=0.8, label='Perfect agreement')\n",
    "ax.set_xlabel('True Null Probability', fontsize=12)\n",
    "ax.set_ylabel('ML-Compositional Null Probability', fontsize=12)\n",
    "ax.set_title(f'ML-Null vs True Null (r={corr:.3f})', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Error by source degree\n",
    "ax = axes[0, 1]\n",
    "source_err = error_analysis_df[error_analysis_df['stratification'] == 'source_degree']\n",
    "ax.bar(range(len(source_err)), source_err['mae'], alpha=0.7)\n",
    "ax.set_xticks(range(len(source_err)))\n",
    "ax.set_xticklabels(source_err['bin'], rotation=45, ha='right')\n",
    "ax.set_xlabel('Source Degree Bin', fontsize=12)\n",
    "ax.set_ylabel('MAE', fontsize=12)\n",
    "ax.set_title('Error by Source Degree', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Error by target degree\n",
    "ax = axes[1, 0]\n",
    "target_err = error_analysis_df[error_analysis_df['stratification'] == 'target_degree']\n",
    "ax.bar(range(len(target_err)), target_err['mae'], alpha=0.7, color='orange')\n",
    "ax.set_xticks(range(len(target_err)))\n",
    "ax.set_xticklabels(target_err['bin'], rotation=45, ha='right')\n",
    "ax.set_xlabel('Target Degree Bin', fontsize=12)\n",
    "ax.set_ylabel('MAE', fontsize=12)\n",
    "ax.set_title('Error by Target Degree', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Distribution comparison\n",
    "ax = axes[1, 1]\n",
    "ax.hist(np.log10(valid_data['true_null_prob'] + 1e-10), bins=50, alpha=0.6, \n",
    "        label='True Null', density=True, edgecolor='black')\n",
    "ax.hist(np.log10(valid_data['ml_null_prob'] + 1e-10), bins=50, alpha=0.6, \n",
    "        label='ML-Compositional Null', density=True, edgecolor='black')\n",
    "ax.set_xlabel('log₁₀(Probability)', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Probability Distributions', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / f'{test_metapath}_validation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved validation plots to {results_dir / f'{test_metapath}_validation.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18843a6b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3473b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save validation data\n",
    "valid_data.to_csv(results_dir / f'{test_metapath}_null_validation.csv', index=False)\n",
    "print(f\"Saved validation data to {results_dir / f'{test_metapath}_null_validation.csv'}\")\n",
    "\n",
    "# Save error analysis\n",
    "error_analysis_df.to_csv(results_dir / f'{test_metapath}_error_analysis.csv', index=False)\n",
    "print(f\"Saved error analysis to {results_dir / f'{test_metapath}_error_analysis.csv'}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary = {\n",
    "    'metapath': test_metapath,\n",
    "    'edge_types': test_edge_types,\n",
    "    'model_type': model_type,\n",
    "    'n_pairs': len(valid_data),\n",
    "    'correlation': corr,\n",
    "    'p_value': p_val,\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'r2': r2,\n",
    "    'ks_stat': ks_stat,\n",
    "    'ks_p': ks_p,\n",
    "    'computation_time_sec': elapsed_time,\n",
    "    'pairs_per_second': len(ml_null_probs)/elapsed_time\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(results_dir / f'{test_metapath}_summary.csv', index=False)\n",
    "print(f\"Saved summary to {results_dir / f'{test_metapath}_summary.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ddf7f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7718ee6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FAST COMPOSITIONAL NULL VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nMetapath: {test_metapath}\")\n",
    "print(f\"Edge types: {' → '.join(test_edge_types)}\")\n",
    "print(f\"Model type: {model_type}\")\n",
    "\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Correlation with true null: r = {corr:.4f} {'✓' if corr > 0.75 else '✗'}\")\n",
    "print(f\"  MAE: {mae:.6e}\")\n",
    "print(f\"  RMSE: {rmse:.6e} {'✓' if rmse < 0.20 else '✗'}\")\n",
    "print(f\"  R²: {r2:.4f} {'✓' if r2 > 0.50 else '✗'}\")\n",
    "\n",
    "print(f\"\\nSpeed:\")\n",
    "print(f\"  Computation time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"  Pairs computed: {len(ml_null_probs):,}\")\n",
    "print(f\"  Speed: {len(ml_null_probs)/elapsed_time:.0f} pairs/second\")\n",
    "\n",
    "print(f\"\\nComparison to Current Method:\")\n",
    "print(f\"  Current degree-aware correlation: 0.065\")\n",
    "print(f\"  ML-compositional correlation: {corr:.4f}\")\n",
    "print(f\"  Improvement: {(corr - 0.065):.4f} ({(corr/0.065 - 1)*100:.1f}% better)\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "for file in results_dir.glob(f'{test_metapath}_*'):\n",
    "    print(f\"  - {file.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/14_fast_compositional_null.ipynb",
   "output_path": "notebooks/executed/14_fast_compositional_null_executed.ipynb",
   "parameters": {},
   "start_time": "2025-10-08T07:15:40.481936",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}