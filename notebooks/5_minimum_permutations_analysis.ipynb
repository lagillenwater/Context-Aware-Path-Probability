{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07bb8a81",
   "metadata": {},
   "source": [
    "# Minimum Permutations Analysis for Edge Probability Learning\n",
    "\n",
    "This notebook implements a systematic approach to determine the minimum number of permutations needed for effective edge probability distribution learning. It progressively trains models using increasing numbers of permutations and measures convergence against empirical frequencies.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. **Progressive Training**: Train models using 1, 2, 3, ... up to max_permutations\n",
    "2. **Performance Evaluation**: Compare predictions against empirical frequencies for each permutation count  \n",
    "3. **Convergence Detection**: Identify when additional permutations provide diminishing returns\n",
    "4. **Optimal Selection**: Determine the minimum number of permutations that achieves target performance\n",
    "\n",
    "## Usage with Papermill\n",
    "\n",
    "```bash\n",
    "papermill 5_minimum_permutations_analysis.ipynb output.ipynb \\\n",
    "  -p edge_type \"AeG\" \\\n",
    "  -p max_permutations 10 \\\n",
    "  -p convergence_threshold 0.05 \\\n",
    "  -p random_seed 42\n",
    "```\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- `edge_type` (str): Type of edge to analyze (default: \"AeG\")\n",
    "- `max_permutations` (int): Maximum number of permutations to test (default: 10)\n",
    "- `convergence_threshold` (float): Performance improvement threshold for convergence (default: 0.05)\n",
    "- `random_seed` (int): Random seed for reproducibility (default: 42)\n",
    "\n",
    "## Output\n",
    "\n",
    "- Performance metrics for each permutation count\n",
    "- Convergence analysis showing diminishing returns\n",
    "- Recommendation for optimal permutation count\n",
    "- Detailed visualizations of learning progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e55e856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies imported successfully\n",
      "Repository directory: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability\n",
      "Source directory: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "repo_dir = Path.cwd().parent\n",
    "src_dir = repo_dir / 'src'\n",
    "sys.path.append(str(src_dir))\n",
    "\n",
    "from data_processing import load_permutation_data, prepare_edge_prediction_data\n",
    "from models import EdgePredictionNN\n",
    "from training import train_edge_prediction_model\n",
    "\n",
    "print(\"All dependencies imported successfully\")\n",
    "print(f\"Repository directory: {repo_dir}\")\n",
    "print(f\"Source directory: {src_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a51a61f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Permutations Analysis Configuration:\n",
      "  Edge type: AeG\n",
      "  Max permutations to test: 10\n",
      "  Convergence threshold: 0.05\n",
      "  Random seed: 42\n",
      "  Performance metric: correlation\n",
      "  Training epochs: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1738ba4d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters (can be overridden by papermill)\n",
    "edge_type = \"AeG\"  # Type of edge to analyze\n",
    "max_permutations = 10  # Maximum number of permutations to test\n",
    "convergence_threshold = 0.05  # Performance improvement threshold for convergence detection\n",
    "random_seed = 42  # Random seed for reproducibility\n",
    "\n",
    "# Training parameters\n",
    "epochs_per_model = 50  # Number of epochs for each model training\n",
    "batch_size = 512  # Batch size for training\n",
    "learning_rate = 0.001  # Learning rate\n",
    "early_stopping_patience = 5  # Early stopping patience\n",
    "\n",
    "# Analysis parameters\n",
    "negative_sampling_ratio = 1.0  # Ratio for negative sampling\n",
    "performance_metric = 'correlation'  # Primary metric for convergence ('mae', 'rmse', 'correlation')\n",
    "\n",
    "print(f\"Minimum Permutations Analysis Configuration:\")\n",
    "print(f\"  Edge type: {edge_type}\")\n",
    "print(f\"  Max permutations to test: {max_permutations}\")\n",
    "print(f\"  Convergence threshold: {convergence_threshold}\")\n",
    "print(f\"  Random seed: {random_seed}\")\n",
    "print(f\"  Performance metric: {performance_metric}\")\n",
    "print(f\"  Training epochs: {epochs_per_model}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import numpy as np\n",
    "import torch\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe6921d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory setup:\n",
      "  Repository: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability\n",
      "  Data: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data\n",
      "  Permutations: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations\n",
      "  Output: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/results/minimum_permutations_basic_2d\n",
      "Loaded 13167 empirical frequency records\n",
      "Degree range - Source: 1-15036\n",
      "Degree range - Target: 1-98\n",
      "Frequency range: 0.000-1.005\n",
      "Discovering available data directories...\n",
      "Original data directory: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data\n",
      "Permutations directory: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations\n",
      "Found 2 permutation directories\n",
      "  1. 000.hetmat\n",
      "  2. 001.hetmat\n",
      "Warning: Only 2 permutations available, but max_permutations = 10\n",
      "   Will reuse permutations if needed.\n",
      "Original edge data found: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/edges/AeG.sparse.npz\n",
      "\n",
      "Data loading and validation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup directories\n",
    "from pathlib import Path\n",
    "\n",
    "repo_dir = Path.cwd().parent\n",
    "data_dir = repo_dir / 'data'\n",
    "permutations_dir = data_dir / 'permutations'\n",
    "downloads_dir = data_dir / 'downloads'\n",
    "models_dir = repo_dir / 'models'\n",
    "output_dir = repo_dir / 'results' / 'minimum_permutations_basic_2d'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directory setup:\")\n",
    "print(f\"  Repository: {repo_dir}\")\n",
    "print(f\"  Data: {data_dir}\")\n",
    "print(f\"  Permutations: {permutations_dir}\")\n",
    "print(f\"  Output: {output_dir}\")\n",
    "\n",
    "def load_empirical_frequencies(results_dir: Path = repo_dir / 'results') -> pd.DataFrame:\n",
    "    \"\"\"Load empirical edge frequencies from CSV file.\"\"\"\n",
    "    freq_file = results_dir / 'edge_frequency_by_degree.csv'\n",
    "    try:\n",
    "        if not freq_file.exists():\n",
    "            raise FileNotFoundError(f\"Empirical frequency file not found: {freq_file}\")\n",
    "        \n",
    "        empirical_freq_df = pd.read_csv(freq_file)\n",
    "        empirical_freq_df = empirical_freq_df.rename(columns={'frequency': 'empirical_frequency'})\n",
    "        \n",
    "        print(f\"Loaded {len(empirical_freq_df)} empirical frequency records\")\n",
    "        print(f\"Degree range - Source: {empirical_freq_df['source_degree'].min()}-{empirical_freq_df['source_degree'].max()}\")\n",
    "        print(f\"Degree range - Target: {empirical_freq_df['target_degree'].min()}-{empirical_freq_df['target_degree'].max()}\")\n",
    "        print(f\"Frequency range: {empirical_freq_df['empirical_frequency'].min():.3f}-{empirical_freq_df['empirical_frequency'].max():.3f}\")\n",
    "        \n",
    "        return empirical_freq_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading empirical frequencies: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_data_directories() -> Tuple[List[Path], Path]:\n",
    "    \"\"\"Validate and discover available data directories.\"\"\"\n",
    "    print(\"Discovering available data directories...\")\n",
    "    \n",
    "    # Find available permutation directories\n",
    "    available_permutations = []\n",
    "    if permutations_dir.exists():\n",
    "        for perm_dir in permutations_dir.iterdir():\n",
    "            if perm_dir.is_dir() and perm_dir.name.endswith('.hetmat'):\n",
    "                available_permutations.append(perm_dir)\n",
    "    \n",
    "    # Sort permutations by name for consistent ordering\n",
    "    permutations_dirs = sorted(available_permutations)\n",
    "    \n",
    "    print(f\"Original data directory: {data_dir}\")\n",
    "    print(f\"Permutations directory: {permutations_dir}\")\n",
    "    print(f\"Found {len(permutations_dirs)} permutation directories\")\n",
    "    \n",
    "    if len(permutations_dirs) <= 5:\n",
    "        for i, perm_dir in enumerate(permutations_dirs):\n",
    "            print(f\"  {i+1}. {perm_dir.name}\")\n",
    "    else:\n",
    "        for i, perm_dir in enumerate(permutations_dirs[:3]):\n",
    "            print(f\"  {i+1}. {perm_dir.name}\")\n",
    "        print(f\"  ... and {len(permutations_dirs) - 3} more\")\n",
    "    \n",
    "    # Validate permutation availability\n",
    "    if len(permutations_dirs) < max_permutations:\n",
    "        print(f\"Warning: Only {len(permutations_dirs)} permutations available, but max_permutations = {max_permutations}\")\n",
    "        print(\"   Will reuse permutations if needed.\")\n",
    "    else:\n",
    "        print(f\"Sufficient permutations available for experiment\")\n",
    "    \n",
    "    # Check original edge data\n",
    "    original_edge_file = data_dir / 'edges' / f\"{edge_type}.sparse.npz\"\n",
    "    if original_edge_file.exists():\n",
    "        print(f\"Original edge data found: {original_edge_file}\")\n",
    "    else:\n",
    "        print(f\"Original edge data not found: {original_edge_file}\")\n",
    "        if (data_dir / 'edges').exists():\n",
    "            edge_files = list((data_dir / 'edges').glob('*.npz'))\n",
    "            print(f\"Available edge files: {[f.name for f in edge_files[:5]]}\")\n",
    "    \n",
    "    return permutations_dirs, original_edge_file\n",
    "\n",
    "# Load data and validate directories\n",
    "empirical_freq_df = load_empirical_frequencies()\n",
    "permutations_dirs, original_edge_file = validate_data_directories()\n",
    "\n",
    "print(\"\\nData loading and validation completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mvme1bjz2nm",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Validation\n",
    "\n",
    "This section loads empirical frequencies and sets up data directories for permutation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a569eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data loading pipeline...\n",
      "Preparing training data using 1 permutations...\n",
      "  Loading permutation 1/1: 000.hetmat\n",
      "Loading data from permutation: 000.hetmat\n",
      "Permutation path: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations/000.hetmat\n",
      "Edge type: AeG (Anatomy -> Gene)\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Preparing AeG edge prediction data (Anatomy -> Gene)\n",
      "Anatomy degree range: 0 - 15036\n",
      "Gene degree range: 0 - 98\n",
      "Number of positive examples (existing edges): 526407\n",
      "Number of positive examples (existing edges): 526407\n",
      "Number of negative examples (non-existing edges): 526407\n",
      "    Added 1052814 samples from 000.hetmat\n",
      "Combined training data: 1052814 total samples from 1 permutations\n",
      "Feature ranges:\n",
      "  Source degrees: 0-15036\n",
      "  Target degrees: 0-98\n",
      "  Edge probabilities: 0.000-1.000\n",
      "Data loading pipeline verified successfully\n",
      "Number of negative examples (non-existing edges): 526407\n",
      "    Added 1052814 samples from 000.hetmat\n",
      "Combined training data: 1052814 total samples from 1 permutations\n",
      "Feature ranges:\n",
      "  Source degrees: 0-15036\n",
      "  Target degrees: 0-98\n",
      "  Edge probabilities: 0.000-1.000\n",
      "Data loading pipeline verified successfully\n"
     ]
    }
   ],
   "source": [
    "def prepare_training_data_from_permutations(permutation_dirs: List[Path], num_permutations: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare training data by combining data from multiple permutations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    permutation_dirs : List[Path]\n",
    "        List of available permutation directories\n",
    "    num_permutations : int\n",
    "        Number of permutations to use for training\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Combined training data from all specified permutations\n",
    "    \"\"\"\n",
    "    print(f\"Preparing training data using {num_permutations} permutations...\")\n",
    "    \n",
    "    if not permutation_dirs:\n",
    "        raise ValueError(\"No permutation directories available\")\n",
    "    \n",
    "    if num_permutations > len(permutation_dirs):\n",
    "        print(f\"Warning: Requested {num_permutations} permutations but only {len(permutation_dirs)} available\")\n",
    "        num_permutations = len(permutation_dirs)\n",
    "    \n",
    "    all_training_data = []\n",
    "    \n",
    "    for i in range(num_permutations):\n",
    "        perm_dir = permutation_dirs[i]\n",
    "        print(f\"  Loading permutation {i+1}/{num_permutations}: {perm_dir.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Load permutation data using proper data processing function\n",
    "            permutation_data = load_permutation_data(\n",
    "                permutation_name=perm_dir.name,\n",
    "                permutations_dir=permutations_dir,\n",
    "                edge_type=edge_type,\n",
    "                source_node_type=\"Anatomy\",\n",
    "                target_node_type=\"Gene\"\n",
    "            )\n",
    "            \n",
    "            # Prepare features and labels for this permutation\n",
    "            features, labels = prepare_edge_prediction_data(\n",
    "                permutation_data,\n",
    "                sample_negative_ratio=negative_sampling_ratio\n",
    "            )\n",
    "            \n",
    "            # Convert to DataFrame and add permutation identifier\n",
    "            perm_df = pd.DataFrame({\n",
    "                'source_degree': features[:, 0],\n",
    "                'target_degree': features[:, 1],\n",
    "                'edge_probability': labels.astype(float),\n",
    "                'permutation_id': i\n",
    "            })\n",
    "            \n",
    "            all_training_data.append(perm_df)\n",
    "            print(f\"    Added {len(perm_df)} samples from {perm_dir.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error loading {perm_dir.name}: {e}\")\n",
    "            # Try alternative loading method\n",
    "            try:\n",
    "                from data_processing_helpers import load_permutation_data as load_perm_helper\n",
    "                from data_processing_helpers import extract_improved_edge_features_and_labels\n",
    "                \n",
    "                edge_matrix, source_degrees, target_degrees = load_perm_helper(perm_dir, edge_type)\n",
    "                features, targets = extract_improved_edge_features_and_labels(\n",
    "                    edge_matrix, source_degrees, target_degrees, \n",
    "                    negative_ratio=negative_sampling_ratio,\n",
    "                    use_normalized_features=False,\n",
    "                    use_regression=True\n",
    "                )\n",
    "                \n",
    "                perm_df = pd.DataFrame({\n",
    "                    'source_degree': features[:, 0],\n",
    "                    'target_degree': features[:, 1],\n",
    "                    'edge_probability': targets,\n",
    "                    'permutation_id': i\n",
    "                })\n",
    "                \n",
    "                all_training_data.append(perm_df)\n",
    "                print(f\"    Alternative loading successful: {len(perm_df)} samples\")\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"    Alternative loading also failed: {e2}\")\n",
    "                continue\n",
    "    \n",
    "    if not all_training_data:\n",
    "        raise ValueError(\"Failed to load any permutation data\")\n",
    "    \n",
    "    # Combine all permutation data\n",
    "    combined_data = pd.concat(all_training_data, ignore_index=True)\n",
    "    \n",
    "    print(f\"Combined training data: {len(combined_data)} total samples from {len(all_training_data)} permutations\")\n",
    "    print(f\"Feature ranges:\")\n",
    "    print(f\"  Source degrees: {combined_data['source_degree'].min():.0f}-{combined_data['source_degree'].max():.0f}\")\n",
    "    print(f\"  Target degrees: {combined_data['target_degree'].min():.0f}-{combined_data['target_degree'].max():.0f}\")\n",
    "    print(f\"  Edge probabilities: {combined_data['edge_probability'].min():.3f}-{combined_data['edge_probability'].max():.3f}\")\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "def train_model_with_n_permutations(num_permutations: int, permutation_dirs: List[Path]) -> Tuple[EdgePredictionNN, Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Train a model using data from n permutations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_permutations : int\n",
    "        Number of permutations to use for training\n",
    "    permutation_dirs : List[Path]\n",
    "        List of available permutation directories\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple[EdgePredictionNN, Dict, Dict]\n",
    "        Trained model, training history, and test metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\nTraining model with {num_permutations} permutations...\")\n",
    "    \n",
    "    # Prepare training data\n",
    "    training_data = prepare_training_data_from_permutations(permutation_dirs, num_permutations)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    features = training_data[['source_degree', 'target_degree']].values.astype(np.float32)\n",
    "    labels = training_data['edge_probability'].values.astype(np.float32)\n",
    "    \n",
    "    print(f\"Training with {len(features)} samples\")\n",
    "    \n",
    "    # Train model using existing utilities\n",
    "    model, train_history, test_metrics = train_edge_prediction_model(\n",
    "        features=features,\n",
    "        labels=labels,\n",
    "        test_size=0.2,\n",
    "        epochs=epochs_per_model,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        patience=early_stopping_patience\n",
    "    )\n",
    "    \n",
    "    print(f\"Training completed. Final train loss: {train_history['train_losses'][-1]:.4f}\")\n",
    "    \n",
    "    return model, train_history, test_metrics\n",
    "\n",
    "# Test with a single permutation first to verify the pipeline\n",
    "print(\"Testing data loading pipeline...\")\n",
    "if permutations_dirs:\n",
    "    test_data = prepare_training_data_from_permutations(permutations_dirs, 1)\n",
    "    print(\"Data loading pipeline verified successfully\")\n",
    "else:\n",
    "    print(\"Warning: No permutation directories found for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2116f126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting progressive analysis with 2 available permutations\n",
      "============================================================\n",
      "PROGRESSIVE PERMUTATION ANALYSIS\n",
      "============================================================\n",
      "Testing 1 to 2 permutations...\n",
      "\n",
      "==================== Testing 1 Permutations ====================\n",
      "\n",
      "Training model with 1 permutations...\n",
      "Preparing training data using 1 permutations...\n",
      "  Loading permutation 1/1: 000.hetmat\n",
      "Loading data from permutation: 000.hetmat\n",
      "Permutation path: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations/000.hetmat\n",
      "Edge type: AeG (Anatomy -> Gene)\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Preparing AeG edge prediction data (Anatomy -> Gene)\n",
      "Anatomy degree range: 0 - 15036\n",
      "Gene degree range: 0 - 98\n",
      "Number of positive examples (existing edges): 526407\n",
      "Number of positive examples (existing edges): 526407\n",
      "Number of negative examples (non-existing edges): 526407\n",
      "    Added 1052814 samples from 000.hetmat\n",
      "Combined training data: 1052814 total samples from 1 permutations\n",
      "Feature ranges:\n",
      "  Source degrees: 0-15036\n",
      "  Target degrees: 0-98\n",
      "  Edge probabilities: 0.000-1.000\n",
      "Training with 1052814 samples\n",
      "Number of negative examples (non-existing edges): 526407\n",
      "    Added 1052814 samples from 000.hetmat\n",
      "Combined training data: 1052814 total samples from 1 permutations\n",
      "Feature ranges:\n",
      "  Source degrees: 0-15036\n",
      "  Target degrees: 0-98\n",
      "  Edge probabilities: 0.000-1.000\n",
      "Training with 1052814 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/CAPP/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 842251 samples, testing on 210563 samples\n",
      "Feature shapes: (842251, 2), Labels shape: (842251,)\n",
      "Early stopping patience: 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 8/50 [01:05<05:46,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 9 epochs\n",
      "Best validation loss: 0.1284 at epoch 4\n",
      "Restored best model weights\n",
      "Final Test AUC: 0.9877\n",
      "Final Test AP: 0.9850\n",
      "Training completed. Final train loss: 0.1318\n",
      "Results for 1 permutations:\n",
      "  MAE: 0.6622\n",
      "  RMSE: 0.7702\n",
      "  Correlation: 0.1508\n",
      "  Train Loss: 0.1318\n",
      "\n",
      "==================== Testing 2 Permutations ====================\n",
      "\n",
      "Training model with 2 permutations...\n",
      "Preparing training data using 2 permutations...\n",
      "  Loading permutation 1/2: 000.hetmat\n",
      "Loading data from permutation: 000.hetmat\n",
      "Permutation path: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations/000.hetmat\n",
      "Edge type: AeG (Anatomy -> Gene)\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Preparing AeG edge prediction data (Anatomy -> Gene)\n",
      "Anatomy degree range: 0 - 15036\n",
      "Gene degree range: 0 - 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive examples (existing edges): 526407\n",
      "Number of negative examples (non-existing edges): 526407\n",
      "    Added 1052814 samples from 000.hetmat\n",
      "  Loading permutation 2/2: 001.hetmat\n",
      "Loading data from permutation: 001.hetmat\n",
      "Permutation path: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations/001.hetmat\n",
      "Edge type: AeG (Anatomy -> Gene)\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Preparing AeG edge prediction data (Anatomy -> Gene)\n",
      "Anatomy degree range: 0 - 15036\n",
      "Gene degree range: 0 - 98\n",
      "Number of negative examples (non-existing edges): 526407\n",
      "    Added 1052814 samples from 000.hetmat\n",
      "  Loading permutation 2/2: 001.hetmat\n",
      "Loading data from permutation: 001.hetmat\n",
      "Permutation path: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations/001.hetmat\n",
      "Edge type: AeG (Anatomy -> Gene)\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Preparing AeG edge prediction data (Anatomy -> Gene)\n",
      "Anatomy degree range: 0 - 15036\n",
      "Gene degree range: 0 - 98\n",
      "Number of positive examples (existing edges): 526407\n",
      "Number of positive examples (existing edges): 526407\n",
      "Number of negative examples (non-existing edges): 526407\n",
      "    Added 1052814 samples from 001.hetmat\n",
      "Combined training data: 2105628 total samples from 2 permutations\n",
      "Feature ranges:\n",
      "  Source degrees: 0-15036\n",
      "  Target degrees: 0-98\n",
      "  Edge probabilities: 0.000-1.000\n",
      "Training with 2105628 samples\n",
      "Number of negative examples (non-existing edges): 526407\n",
      "    Added 1052814 samples from 001.hetmat\n",
      "Combined training data: 2105628 total samples from 2 permutations\n",
      "Feature ranges:\n",
      "  Source degrees: 0-15036\n",
      "  Target degrees: 0-98\n",
      "  Edge probabilities: 0.000-1.000\n",
      "Training with 2105628 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/CAPP/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1684502 samples, testing on 421126 samples\n",
      "Feature shapes: (1684502, 2), Labels shape: (1684502,)\n",
      "Early stopping patience: 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 10/50 [02:34<10:21, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: Train Loss: 0.1309, Val Loss: 0.1282, Val AUC: 0.9877, LR: 1.00e-03, Best Val Loss: 0.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 20/50 [05:10<07:40, 15.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: Train Loss: 0.1307, Val Loss: 0.1272, Val AUC: 0.9878, LR: 1.00e-03, Best Val Loss: 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 25/50 [06:44<06:44, 16.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 26 epochs\n",
      "Best validation loss: 0.1269 at epoch 21\n",
      "Restored best model weights\n",
      "Final Test AUC: 0.9878\n",
      "Final Test AP: 0.9851\n",
      "Training completed. Final train loss: 0.1306\n",
      "Results for 2 permutations:\n",
      "  MAE: 0.3046\n",
      "  RMSE: 0.4855\n",
      "  Correlation: -0.0310\n",
      "  Train Loss: 0.1306\n",
      "  Improvement in correlation: -0.1819\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE\n",
      "============================================================\n",
      "Optimal number of permutations: 1\n",
      "Convergence detected at: 1 permutations\n",
      "Final performance - MAE: 0.3046, Correlation: -0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_against_empirical(model: EdgePredictionNN, empirical_freq_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate model predictions against empirical frequencies.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : EdgePredictionNN\n",
    "        Trained model to evaluate\n",
    "    empirical_freq_df : pd.DataFrame\n",
    "        DataFrame with empirical frequencies\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict\n",
    "        Performance metrics including MAE, RMSE, correlation\n",
    "    \"\"\"\n",
    "    # Prepare input features\n",
    "    test_features = empirical_freq_df[['source_degree', 'target_degree']].values.astype(np.float32)\n",
    "    test_tensor = torch.tensor(test_features)\n",
    "    \n",
    "    # Generate predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(test_tensor).squeeze().numpy()\n",
    "    \n",
    "    predictions = np.clip(predictions, 0.0, 1.0)\n",
    "    empirical_values = empirical_freq_df['empirical_frequency'].values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(predictions - empirical_values))\n",
    "    rmse = np.sqrt(np.mean((predictions - empirical_values) ** 2))\n",
    "    correlation = np.corrcoef(predictions, empirical_values)[0, 1]\n",
    "    \n",
    "    # Handle NaN correlation (can occur with constant predictions)\n",
    "    if np.isnan(correlation):\n",
    "        correlation = 0.0\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'correlation': correlation,\n",
    "        'predictions': predictions,\n",
    "        'empirical': empirical_values\n",
    "    }\n",
    "\n",
    "def run_progressive_permutation_analysis(permutation_dirs: List[Path], empirical_freq_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run the complete progressive permutation analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    permutation_dirs : List[Path]\n",
    "        List of available permutation directories\n",
    "    empirical_freq_df : pd.DataFrame\n",
    "        DataFrame with empirical frequencies for evaluation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Results dataframe with performance metrics for each permutation count\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"PROGRESSIVE PERMUTATION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results = []\n",
    "    max_perms_to_test = min(max_permutations, len(permutation_dirs))\n",
    "    \n",
    "    print(f\"Testing 1 to {max_perms_to_test} permutations...\")\n",
    "    \n",
    "    for num_perms in range(1, max_perms_to_test + 1):\n",
    "        print(f\"\\n{'='*20} Testing {num_perms} Permutations {'='*20}\")\n",
    "        \n",
    "        try:\n",
    "            # Train model with n permutations\n",
    "            model, train_history, test_metrics = train_model_with_n_permutations(num_perms, permutation_dirs)\n",
    "            \n",
    "            # Evaluate against empirical frequencies\n",
    "            evaluation_results = evaluate_model_against_empirical(model, empirical_freq_df)\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'num_permutations': num_perms,\n",
    "                'mae': evaluation_results['mae'],\n",
    "                'rmse': evaluation_results['rmse'],\n",
    "                'correlation': evaluation_results['correlation'],\n",
    "                'train_loss': train_history['train_losses'][-1],\n",
    "                'test_auc': test_metrics.get('auc', 0.0),\n",
    "                'test_ap': test_metrics.get('average_precision', 0.0)\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"Results for {num_perms} permutations:\")\n",
    "            print(f\"  MAE: {result['mae']:.4f}\")\n",
    "            print(f\"  RMSE: {result['rmse']:.4f}\")\n",
    "            print(f\"  Correlation: {result['correlation']:.4f}\")\n",
    "            print(f\"  Train Loss: {result['train_loss']:.4f}\")\n",
    "            \n",
    "            # Check for convergence if we have enough data points\n",
    "            if len(results) >= 2:\n",
    "                current_metric = result[performance_metric] if performance_metric != 'mae' and performance_metric != 'rmse' else -result[performance_metric]\n",
    "                previous_metric = results[-2][performance_metric] if performance_metric != 'mae' and performance_metric != 'rmse' else -results[-2][performance_metric]\n",
    "                improvement = current_metric - previous_metric\n",
    "                \n",
    "                print(f\"  Improvement in {performance_metric}: {improvement:.4f}\")\n",
    "                \n",
    "                if abs(improvement) < convergence_threshold:\n",
    "                    print(f\"  Convergence detected! Improvement ({abs(improvement):.4f}) below threshold ({convergence_threshold})\")\n",
    "                    break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training with {num_perms} permutations: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def analyze_convergence(results_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze convergence patterns in the results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_df : pd.DataFrame\n",
    "        Results from progressive permutation analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict\n",
    "        Convergence analysis results\n",
    "    \"\"\"\n",
    "    if len(results_df) < 2:\n",
    "        return {\"message\": \"Insufficient data for convergence analysis\"}\n",
    "    \n",
    "    # Find optimal permutation count based on primary metric\n",
    "    if performance_metric == 'correlation':\n",
    "        best_idx = results_df['correlation'].idxmax()\n",
    "        best_value = results_df['correlation'].max()\n",
    "    elif performance_metric == 'mae':\n",
    "        best_idx = results_df['mae'].idxmin()\n",
    "        best_value = results_df['mae'].min()\n",
    "    elif performance_metric == 'rmse':\n",
    "        best_idx = results_df['rmse'].idxmin()\n",
    "        best_value = results_df['rmse'].min()\n",
    "    else:\n",
    "        best_idx = results_df['correlation'].idxmax()\n",
    "        best_value = results_df['correlation'].max()\n",
    "    \n",
    "    optimal_permutations = results_df.loc[best_idx, 'num_permutations']\n",
    "    \n",
    "    # Calculate improvement curves\n",
    "    results_df['mae_improvement'] = results_df['mae'].diff().fillna(0)\n",
    "    results_df['rmse_improvement'] = results_df['rmse'].diff().fillna(0)\n",
    "    results_df['correlation_improvement'] = results_df['correlation'].diff().fillna(0)\n",
    "    \n",
    "    # Find first point where improvement falls below threshold\n",
    "    if performance_metric == 'correlation':\n",
    "        convergence_points = results_df[abs(results_df['correlation_improvement']) < convergence_threshold]\n",
    "    elif performance_metric == 'mae':\n",
    "        convergence_points = results_df[abs(results_df['mae_improvement']) < convergence_threshold]\n",
    "    else:\n",
    "        convergence_points = results_df[abs(results_df['correlation_improvement']) < convergence_threshold]\n",
    "    \n",
    "    if len(convergence_points) > 0:\n",
    "        convergence_permutations = convergence_points.iloc[0]['num_permutations']\n",
    "    else:\n",
    "        convergence_permutations = results_df.iloc[-1]['num_permutations']\n",
    "    \n",
    "    return {\n",
    "        'optimal_permutations': int(optimal_permutations),\n",
    "        'optimal_value': best_value,\n",
    "        'convergence_permutations': int(convergence_permutations),\n",
    "        'total_tested': len(results_df),\n",
    "        'final_mae': results_df.iloc[-1]['mae'],\n",
    "        'final_rmse': results_df.iloc[-1]['rmse'],\n",
    "        'final_correlation': results_df.iloc[-1]['correlation']\n",
    "    }\n",
    "\n",
    "# Run the progressive analysis\n",
    "if permutations_dirs:\n",
    "    print(f\"Starting progressive analysis with {len(permutations_dirs)} available permutations\")\n",
    "    results_df = run_progressive_permutation_analysis(permutations_dirs, empirical_freq_df)\n",
    "    convergence_analysis = analyze_convergence(results_df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Optimal number of permutations: {convergence_analysis['optimal_permutations']}\")\n",
    "    print(f\"Convergence detected at: {convergence_analysis['convergence_permutations']} permutations\")\n",
    "    print(f\"Final performance - MAE: {convergence_analysis['final_mae']:.4f}, Correlation: {convergence_analysis['final_correlation']:.4f}\")\n",
    "else:\n",
    "    print(\"No permutation directories available for analysis\")\n",
    "    results_df = pd.DataFrame()\n",
    "    convergence_analysis = {\"message\": \"No data available\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fyieo68hf1f",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation & Prediction Analysis\n",
    "\n",
    "This section evaluates the trained model and compares predictions with empirical frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "gze7l69l0nd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model predictions...\n",
      "Prediction Quality Metrics:\n",
      "  Mean Absolute Error: 0.6115\n",
      "  Root Mean Square Error: 0.7365\n",
      "  Median Absolute Error: 0.8333\n",
      "  Pearson Correlation: 0.2401\n",
      "Demonstrating predictions for 10 example degree pairs...\n",
      "Sample Predictions:\n",
      "Source Deg | Target Deg | Predicted Probability\n",
      "---------------------------------------------\n",
      "       10 |         5 |            1.0000\n",
      "       20 |        15 |            1.0000\n",
      "       50 |        25 |            1.0000\n",
      "      100 |        50 |            1.0000\n",
      "      200 |       100 |            1.0000\n",
      "        5 |       100 |            0.0000\n",
      "       15 |       200 |            0.0000\n",
      "       25 |       300 |            0.0000\n",
      "        0 |        10 |            0.0000\n",
      "      500 |      1000 |            1.0000\n",
      "Model evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_predictions(model: EdgePredictionNN, empirical_freq_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Evaluate model predictions against empirical frequencies.\"\"\"\n",
    "    \n",
    "    print(\"Evaluating model predictions...\")\n",
    "    \n",
    "    # Prepare input features from empirical data\n",
    "    test_features = empirical_freq_df[['source_degree', 'target_degree']].values.astype(np.float32)\n",
    "    test_tensor = torch.tensor(test_features)\n",
    "    \n",
    "    # Generate predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        raw_predictions = model(test_tensor).squeeze().numpy()\n",
    "    \n",
    "    # Ensure predictions are valid probabilities\n",
    "    predictions = raw_predictions\n",
    "    # predictions = np.clip(raw_predictions, 0.0, 1.0)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = empirical_freq_df.copy()\n",
    "    results_df['predicted_probability'] = predictions\n",
    "    results_df['prediction_error'] = np.abs(results_df['predicted_probability'] - results_df['empirical_frequency'])\n",
    "    results_df['relative_error'] = results_df['prediction_error'] / (results_df['empirical_frequency'] + 1e-8)\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    mae = results_df['prediction_error'].mean()\n",
    "    rmse = np.sqrt((results_df['prediction_error'] ** 2).mean())\n",
    "    median_error = results_df['prediction_error'].median()\n",
    "    correlation = results_df['predicted_probability'].corr(results_df['empirical_frequency'])\n",
    "    \n",
    "    print(f\"Prediction Quality Metrics:\")\n",
    "    print(f\"  Mean Absolute Error: {mae:.4f}\")\n",
    "    print(f\"  Root Mean Square Error: {rmse:.4f}\")\n",
    "    print(f\"  Median Absolute Error: {median_error:.4f}\")\n",
    "    print(f\"  Pearson Correlation: {correlation:.4f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def demonstrate_edge_predictions(model: EdgePredictionNN, n_examples: int = 10):\n",
    "    \"\"\"Demonstrate edge probability predictions for sample degree pairs.\"\"\"\n",
    "    \n",
    "    print(f\"Demonstrating predictions for {n_examples} example degree pairs...\")\n",
    "    \n",
    "    # Create sample degree pairs with diverse ranges\n",
    "    example_pairs = [\n",
    "        (10, 5), (20, 15), (50, 25), (100, 50), (200, 100),\n",
    "        (5, 100), (15, 200), (25, 300), (0, 10), (500, 1000)\n",
    "    ][:n_examples]\n",
    "    \n",
    "    test_features = np.array(example_pairs, dtype=np.float32)\n",
    "    test_tensor = torch.tensor(test_features)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(test_tensor).squeeze().numpy()\n",
    "    \n",
    "    predictions = np.clip(predictions, 0.0, 1.0)\n",
    "    \n",
    "    print(\"Sample Predictions:\")\n",
    "    print(\"Source Deg | Target Deg | Predicted Probability\")\n",
    "    print(\"-\" * 45)\n",
    "    for i, (src_deg, tgt_deg) in enumerate(example_pairs):\n",
    "        print(f\"{src_deg:>9} | {tgt_deg:>9} | {predictions[i]:>17.4f}\")\n",
    "    \n",
    "    return example_pairs, predictions\n",
    "\n",
    "# Evaluate the model\n",
    "results_df = evaluate_model_predictions(model, empirical_freq_df)\n",
    "\n",
    "# Demonstrate predictions\n",
    "example_pairs, example_predictions = demonstrate_edge_predictions(model)\n",
    "\n",
    "print(\"Model evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zko9oechec",
   "metadata": {},
   "source": [
    "## 5. Results Visualization & Analysis\n",
    "\n",
    "This section provides visualization of training progress and prediction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ce4b18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_degree</th>\n",
       "      <th>target_degree</th>\n",
       "      <th>empirical_frequency</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>prediction_error</th>\n",
       "      <th>relative_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7939</td>\n",
       "      <td>20</td>\n",
       "      <td>0.272037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727963</td>\n",
       "      <td>2.675964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7939</td>\n",
       "      <td>75</td>\n",
       "      <td>0.979326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>0.021110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7939</td>\n",
       "      <td>38</td>\n",
       "      <td>0.627020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.372980</td>\n",
       "      <td>0.594846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7939</td>\n",
       "      <td>56</td>\n",
       "      <td>0.874961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125039</td>\n",
       "      <td>0.142908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7939</td>\n",
       "      <td>67</td>\n",
       "      <td>0.954649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045351</td>\n",
       "      <td>0.047505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13162</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>121732.629836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13163</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>87642.120332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13164</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>60754.066388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13165</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>87031.188872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13166</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>76033.144859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13167 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source_degree  target_degree  empirical_frequency  \\\n",
       "0               7939             20             0.272037   \n",
       "1               7939             75             0.979326   \n",
       "2               7939             38             0.627020   \n",
       "3               7939             56             0.874961   \n",
       "4               7939             67             0.954649   \n",
       "...              ...            ...                  ...   \n",
       "13162             56              3             0.000008   \n",
       "13163            101              1             0.000011   \n",
       "13164             25              3             0.000016   \n",
       "13165             46              5             0.000011   \n",
       "13166             25              7             0.000013   \n",
       "\n",
       "       predicted_probability  prediction_error  relative_error  \n",
       "0                        1.0          0.727963        2.675964  \n",
       "1                        1.0          0.020674        0.021110  \n",
       "2                        1.0          0.372980        0.594846  \n",
       "3                        1.0          0.125039        0.142908  \n",
       "4                        1.0          0.045351        0.047505  \n",
       "...                      ...               ...             ...  \n",
       "13162                    1.0          0.999992   121732.629836  \n",
       "13163                    1.0          0.999989    87642.120332  \n",
       "13164                    1.0          0.999984    60754.066388  \n",
       "13165                    1.0          0.999989    87031.188872  \n",
       "13166                    1.0          0.999987    76033.144859  \n",
       "\n",
       "[13167 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oqhsdq9js3o",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progressive_analysis_results(results_df: pd.DataFrame, convergence_analysis: Dict, figsize: Tuple[int, int] = (15, 12), x = max_permutations):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations of the progressive permutation analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_df : pd.DataFrame\n",
    "        Results from progressive analysis\n",
    "    convergence_analysis : Dict\n",
    "        Convergence analysis results\n",
    "    figsize : Tuple[int, int]\n",
    "        Figure size for plots\n",
    "    x : int\n",
    "        Number of permutations\n",
    "    \"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        print(\"No results to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "    \n",
    "    # 1. Performance metrics vs number of permutations\n",
    " \n",
    "    axes[0,0].plot(x, results_df['mae'], 'b-o', label='MAE', linewidth=2, markersize=6)\n",
    "    axes[0,0].plot(x, results_df['rmse'], 'r-s', label='RMSE', linewidth=2, markersize=6)\n",
    "    axes[0,0].axvline(convergence_analysis.get('optimal_permutations', 0), color='green', linestyle='--', alpha=0.7, label='Optimal')\n",
    "    axes[0,0].axvline(convergence_analysis.get('convergence_permutations', 0), color='orange', linestyle='--', alpha=0.7, label='Convergence')\n",
    "    axes[0,0].set_xlabel('Number of Permutations')\n",
    "    axes[0,0].set_ylabel('Error')\n",
    "    axes[0,0].set_title('Error Metrics vs Permutations')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Correlation vs number of permutations\n",
    "    axes[0,1].plot(x, results_df['correlation'], 'g-^', label='Correlation', linewidth=2, markersize=6)\n",
    "    axes[0,1].axvline(convergence_analysis.get('optimal_permutations', 0), color='green', linestyle='--', alpha=0.7, label='Optimal')\n",
    "    axes[0,1].axvline(convergence_analysis.get('convergence_permutations', 0), color='orange', linestyle='--', alpha=0.7, label='Convergence')\n",
    "    axes[0,1].set_xlabel('Number of Permutations')\n",
    "    axes[0,1].set_ylabel('Correlation with Empirical')\n",
    "    axes[0,1].set_title('Correlation vs Permutations')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Training loss vs number of permutations\n",
    "    axes[0,2].plot(x, results_df['train_loss'], 'm-d', label='Train Loss', linewidth=2, markersize=6)\n",
    "    axes[0,2].axvline(convergence_analysis.get('optimal_permutations', 0), color='green', linestyle='--', alpha=0.7, label='Optimal')\n",
    "    axes[0,2].set_xlabel('Number of Permutations')\n",
    "    axes[0,2].set_ylabel('Final Training Loss')\n",
    "    axes[0,2].set_title('Training Loss vs Permutations')\n",
    "    axes[0,2].legend()\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Improvement curves (if enough data points)\n",
    "    if len(results_df) > 1:\n",
    "        mae_improvement = results_df['mae'].diff().fillna(0)\n",
    "        correlation_improvement = results_df['correlation'].diff().fillna(0)\n",
    "        \n",
    "        axes[1,0].plot(x[1:], mae_improvement[1:], 'b-o', label='MAE Improvement', linewidth=2)\n",
    "        axes[1,0].axhline(convergence_threshold, color='red', linestyle='--', alpha=0.7, label=f'Threshold ({convergence_threshold})')\n",
    "        axes[1,0].axhline(-convergence_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "        axes[1,0].set_xlabel('Number of Permutations')\n",
    "        axes[1,0].set_ylabel('Change in MAE')\n",
    "        axes[1,0].set_title('MAE Improvement per Additional Permutation')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1,1].plot(x[1:], correlation_improvement[1:], 'g-^', label='Correlation Improvement', linewidth=2)\n",
    "        axes[1,1].axhline(convergence_threshold, color='red', linestyle='--', alpha=0.7, label=f'Threshold ({convergence_threshold})')\n",
    "        axes[1,1].axhline(-convergence_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "        axes[1,1].set_xlabel('Number of Permutations')\n",
    "        axes[1,1].set_ylabel('Change in Correlation')\n",
    "        axes[1,1].set_title('Correlation Improvement per Additional Permutation')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1,0].text(0.5, 0.5, 'Insufficient data\\nfor improvement analysis', ha='center', va='center', transform=axes[1,0].transAxes)\n",
    "        axes[1,1].text(0.5, 0.5, 'Insufficient data\\nfor improvement analysis', ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "    \n",
    "    # 5. Performance summary bar chart\n",
    "    metrics = ['MAE', 'RMSE', 'Correlation']\n",
    "    if len(results_df) > 0:\n",
    "        final_values = [results_df.iloc[-1]['mae'], results_df.iloc[-1]['rmse'], results_df.iloc[-1]['correlation']]\n",
    "        optimal_idx = convergence_analysis.get('optimal_permutations', 1) - 1\n",
    "        if optimal_idx < len(results_df):\n",
    "            optimal_values = [results_df.iloc[optimal_idx]['mae'], results_df.iloc[optimal_idx]['rmse'], results_df.iloc[optimal_idx]['correlation']]\n",
    "        else:\n",
    "            optimal_values = final_values\n",
    "        \n",
    "        x_pos = np.arange(len(metrics))\n",
    "        width = 0.35\n",
    "        \n",
    "        axes[1,2].bar(x_pos - width/2, [final_values[0], final_values[1], final_values[2]], width, \n",
    "                     label=f'Final ({len(results_df)} perms)', alpha=0.7)\n",
    "        axes[1,2].bar(x_pos + width/2, [optimal_values[0], optimal_values[1], optimal_values[2]], width, \n",
    "                     label=f'Optimal ({convergence_analysis.get(\"optimal_permutations\", \"N/A\")} perms)', alpha=0.7)\n",
    "        \n",
    "        axes[1,2].set_xlabel('Metrics')\n",
    "        axes[1,2].set_ylabel('Values')\n",
    "        axes[1,2].set_title('Final vs Optimal Performance')\n",
    "        axes[1,2].set_xticks(x_pos)\n",
    "        axes[1,2].set_xticklabels(metrics)\n",
    "        axes[1,2].legend()\n",
    "        axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_analysis_results(results_df: pd.DataFrame, convergence_analysis: Dict):\n",
    "    \"\"\"Save the analysis results to files.\"\"\"\n",
    "    \n",
    "    # Save detailed results\n",
    "    results_file = output_dir / f'progressive_analysis_results_{edge_type}.csv'\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    \n",
    "    # Save convergence analysis\n",
    "    convergence_file = output_dir / f'convergence_analysis_{edge_type}.json'\n",
    "    import json\n",
    "    with open(convergence_file, 'w') as f:\n",
    "        json.dump(convergence_analysis, f, indent=2, default=str)\n",
    "    \n",
    "    # Save summary report\n",
    "    summary_file = output_dir / f'minimum_permutations_summary_{edge_type}.txt'\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"MINIMUM PERMUTATIONS ANALYSIS SUMMARY\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        f.write(f\"Edge Type: {edge_type}\\n\")\n",
    "        f.write(f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Performance Metric: {performance_metric}\\n\")\n",
    "        f.write(f\"Convergence Threshold: {convergence_threshold}\\n\\n\")\n",
    "        \n",
    "        if 'optimal_permutations' in convergence_analysis:\n",
    "            f.write(f\"RESULTS:\\n\")\n",
    "            f.write(f\"- Optimal number of permutations: {convergence_analysis['optimal_permutations']}\\n\")\n",
    "            f.write(f\"- Convergence detected at: {convergence_analysis['convergence_permutations']} permutations\\n\")\n",
    "            f.write(f\"- Total permutations tested: {convergence_analysis['total_tested']}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"FINAL PERFORMANCE:\\n\")\n",
    "            f.write(f\"- MAE: {convergence_analysis['final_mae']:.4f}\\n\")\n",
    "            f.write(f\"- RMSE: {convergence_analysis['final_rmse']:.4f}\\n\")\n",
    "            f.write(f\"- Correlation: {convergence_analysis['final_correlation']:.4f}\\n\\n\")\n",
    "        else:\n",
    "            f.write(f\"RESULTS: {convergence_analysis.get('message', 'Analysis incomplete')}\\n\")\n",
    "    \n",
    "    print(f\"Analysis results saved:\")\n",
    "    print(f\"  Detailed results: {results_file}\")\n",
    "    print(f\"  Convergence analysis: {convergence_file}\")\n",
    "    print(f\"  Summary report: {summary_file}\")\n",
    "\n",
    "def print_final_analysis_report(results_df: pd.DataFrame, convergence_analysis: Dict):\n",
    "    \"\"\"Print a comprehensive final report.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MINIMUM PERMUTATIONS ANALYSIS - FINAL REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if 'optimal_permutations' in convergence_analysis:\n",
    "        print(f\"\\nRECOMMENDATION:\")\n",
    "        print(f\"  Minimum effective permutations: {convergence_analysis['optimal_permutations']}\")\n",
    "        print(f\"  Convergence detected at: {convergence_analysis['convergence_permutations']} permutations\")\n",
    "        \n",
    "        print(f\"\\nPERFORMANCE ACHIEVED:\")\n",
    "        print(f\"  Mean Absolute Error: {convergence_analysis['final_mae']:.4f}\")\n",
    "        print(f\"  Root Mean Square Error: {convergence_analysis['final_rmse']:.4f}\")\n",
    "        print(f\"  Correlation with Empirical: {convergence_analysis['final_correlation']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nANALYSIS DETAILS:\")\n",
    "        print(f\"  Total permutations tested: {convergence_analysis['total_tested']}\")\n",
    "        print(f\"  Primary performance metric: {performance_metric}\")\n",
    "        print(f\"  Convergence threshold: {convergence_threshold}\")\n",
    "        \n",
    "        if len(results_df) > 1:\n",
    "            improvement_1_to_2 = results_df.iloc[1]['correlation'] - results_df.iloc[0]['correlation'] if len(results_df) > 1 else 0\n",
    "            print(f\"  Improvement from 1 to 2 permutations: {improvement_1_to_2:.4f}\")\n",
    "        \n",
    "        print(f\"\\nINTERPRETATION:\")\n",
    "        if convergence_analysis['optimal_permutations'] == 1:\n",
    "            print(\"  - Single permutation provides optimal performance\")\n",
    "            print(\"  - Additional permutations may not improve learning significantly\")\n",
    "        elif convergence_analysis['optimal_permutations'] <= 3:\n",
    "            print(\"  - Few permutations needed for effective learning\")\n",
    "            print(\"  - Model converges quickly with limited data diversity\")\n",
    "        else:\n",
    "            print(\"  - Multiple permutations required for optimal performance\")\n",
    "            print(\"  - Model benefits from increased data diversity\")\n",
    "    else:\n",
    "        print(f\"\\nANALYSIS INCOMPLETE: {convergence_analysis.get('message', 'Unknown error')}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Create visualizations and save results\n",
    "if len(results_df) > 0:\n",
    "    print(\"Creating visualization of progressive analysis results...\")\n",
    "    plot_progressive_analysis_results(results_df, convergence_analysis, x = min(len(permutations_dirs), max_permutations))\n",
    "    \n",
    "    print(\"Saving analysis results...\")\n",
    "    save_analysis_results(results_df, convergence_analysis)\n",
    "    \n",
    "    print_final_analysis_report(results_df, convergence_analysis)\n",
    "else:\n",
    "    print(\"No results available for visualization and reporting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mys4xdxa46",
   "metadata": {},
   "source": [
    "## 6. Summary & Conclusions\n",
    "\n",
    "This section provides a summary of the analysis and potential next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ioo2a2khu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Analysis Configuration and Results\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MINIMUM PERMUTATIONS ANALYSIS CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Analysis Parameters:\")\n",
    "print(f\"  Edge type analyzed: {edge_type}\")\n",
    "print(f\"  Maximum permutations tested: {max_permutations}\")\n",
    "print(f\"  Convergence threshold: {convergence_threshold}\")\n",
    "print(f\"  Performance metric: {performance_metric}\")\n",
    "print(f\"  Random seed: {random_seed}\")\n",
    "\n",
    "print(f\"\\nTraining Parameters:\")\n",
    "print(f\"  Epochs per model: {epochs_per_model}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
    "print(f\"  Negative sampling ratio: {negative_sampling_ratio}\")\n",
    "\n",
    "if 'optimal_permutations' in convergence_analysis:\n",
    "    print(f\"\\nKey Findings:\")\n",
    "    print(f\"  - Minimum effective permutations: {convergence_analysis['optimal_permutations']}\")\n",
    "    print(f\"  - Model performance stabilizes at: {convergence_analysis['convergence_permutations']} permutations\")\n",
    "    print(f\"  - Final correlation with empirical data: {convergence_analysis['final_correlation']:.4f}\")\n",
    "    print(f\"  - Final mean absolute error: {convergence_analysis['final_mae']:.4f}\")\n",
    "\n",
    "print(f\"\\nFiles Generated:\")\n",
    "print(f\"  - Results: {output_dir}/progressive_analysis_results_{edge_type}.csv\")\n",
    "print(f\"  - Convergence Analysis: {output_dir}/convergence_analysis_{edge_type}.json\")  \n",
    "print(f\"  - Summary Report: {output_dir}/minimum_permutations_summary_{edge_type}.txt\")\n",
    "\n",
    "print(f\"\\nReproducibility:\")\n",
    "print(f\"  Run with papermill using:\")\n",
    "print(f\"  papermill 5_minimum_permutations_analysis.ipynb output.ipynb \\\\\")\n",
    "print(f\"    -p edge_type '{edge_type}' \\\\\")\n",
    "print(f\"    -p max_permutations {max_permutations} \\\\\")\n",
    "print(f\"    -p convergence_threshold {convergence_threshold} \\\\\")\n",
    "print(f\"    -p random_seed {random_seed}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vnijceo3gpk",
   "metadata": {},
   "source": [
    "## 3. Neural Network Training\n",
    "\n",
    "This section trains the edge prediction model using the existing EdgePredictionNN architecture and training utilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAPP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
