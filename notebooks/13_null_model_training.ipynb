{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Model Training\n",
    "\n",
    "This notebook trains ML models on null networks (degree-preserving permutations) to create degree-aware null models.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Train models that predict edge probabilities based **only** on degree structure (no biological signal):\n",
    "- **Training data**: Permutations 1-20 (null networks)\n",
    "- **Validation data**: Permutations 21-30 (held-out nulls)\n",
    "- **Test data**: Hetionet (perm 0) vs validation nulls\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **No data leakage**: Hetionet never seen during training\n",
    "- **Two models**: Polynomial Logistic Regression (fast) + Random Forest (accurate)\n",
    "- **Error analysis**: Performance stratified by degree bins\n",
    "- **All 24 edge types**: Complete null model library\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Load null edge frequencies (perms 1-20)\n",
    "2. Train Polynomial LogReg and Random Forest\n",
    "3. Validate on held-out nulls (perms 21-30)\n",
    "4. Error analysis by degree\n",
    "5. Save models and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Papermill parameters\n",
    "training_perm_range = (1, 21)  # Permutations 1-20 for training\n",
    "validation_perm_range = (21, 31)  # Permutations 21-30 for validation\n",
    "edge_types_to_process = None  # None = all 24 edge types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import pearsonr\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "repo_dir = Path.cwd()\n",
    "data_dir = repo_dir / 'data'\n",
    "results_dir = repo_dir / 'results' / 'null_models'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Repository directory: {repo_dir}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Results will be saved to: {results_dir}\")\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Edge Types and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All 24 edge types\n",
    "ALL_EDGE_TYPES = [\n",
    "    \"AdG\", \"AeG\", \"AuG\", \"CbG\", \"CcSE\", \"CdG\", \"CpD\", \"CrC\", \"CtD\", \"CuG\",\n",
    "    \"DaG\", \"DdG\", \"DlA\", \"DpS\", \"DrD\", \"DuG\", \"GcG\", \"GiG\", \"GpBP\", \"GpCC\",\n",
    "    \"GpMF\", \"GpPW\", \"Gr>G\", \"PCiC\"\n",
    "]\n",
    "\n",
    "# Use provided edge_types or default to all\n",
    "if edge_types_to_process is None:\n",
    "    edge_types_to_process = ALL_EDGE_TYPES\n",
    "\n",
    "print(f\"Processing {len(edge_types_to_process)} edge types\")\n",
    "print(f\"Training permutations: {training_perm_range[0]}-{training_perm_range[1]-1}\")\n",
    "print(f\"Validation permutations: {validation_perm_range[0]}-{validation_perm_range[1]-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_null_edge_frequencies(edge_type, perm_ids, negative_sample_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Load and aggregate edge frequencies from null permutations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    edge_type : str\n",
    "        Edge type (e.g., 'CbG')\n",
    "    perm_ids : list or range\n",
    "        Permutation IDs to load\n",
    "    negative_sample_ratio : float\n",
    "        Ratio of negative samples to positive samples\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with columns: source_degree, target_degree, edge_probability\n",
    "    \"\"\"\n",
    "    all_pairs = []\n",
    "    \n",
    "    for perm_id in perm_ids:\n",
    "        edge_file = data_dir / 'permutations' / f'{perm_id:03d}.hetmat' / 'edges' / f'{edge_type}.sparse.npz'\n",
    "        \n",
    "        if not edge_file.exists():\n",
    "            print(f\"  Warning: File not found: {edge_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Load edge matrix\n",
    "        matrix = sp.load_npz(str(edge_file))\n",
    "        source_degrees = np.array(matrix.sum(axis=1)).flatten()\n",
    "        target_degrees = np.array(matrix.sum(axis=0)).flatten()\n",
    "        \n",
    "        # Positive examples (edges)\n",
    "        for i, j in zip(*matrix.nonzero()):\n",
    "            all_pairs.append({\n",
    "                'source_degree': int(source_degrees[i]),\n",
    "                'target_degree': int(target_degrees[j]),\n",
    "                'edge_exists': 1\n",
    "            })\n",
    "        \n",
    "        # Negative examples (sample non-edges)\n",
    "        n_nodes_source, n_nodes_target = matrix.shape\n",
    "        n_negatives = int(matrix.nnz * negative_sample_ratio)\n",
    "        \n",
    "        sampled = 0\n",
    "        attempts = 0\n",
    "        max_attempts = n_negatives * 10\n",
    "        \n",
    "        while sampled < n_negatives and attempts < max_attempts:\n",
    "            i = np.random.randint(0, n_nodes_source)\n",
    "            j = np.random.randint(0, n_nodes_target)\n",
    "            \n",
    "            if matrix[i, j] == 0 and source_degrees[i] > 0 and target_degrees[j] > 0:\n",
    "                all_pairs.append({\n",
    "                    'source_degree': int(source_degrees[i]),\n",
    "                    'target_degree': int(target_degrees[j]),\n",
    "                    'edge_exists': 0\n",
    "                })\n",
    "                sampled += 1\n",
    "            attempts += 1\n",
    "    \n",
    "    # Convert to DataFrame and aggregate\n",
    "    df = pd.DataFrame(all_pairs)\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        return pd.DataFrame(columns=['source_degree', 'target_degree', 'edge_probability'])\n",
    "    \n",
    "    # Aggregate by degree pair\n",
    "    null_freq = df.groupby(['source_degree', 'target_degree']).agg({\n",
    "        'edge_exists': ['sum', 'count', 'mean']\n",
    "    }).reset_index()\n",
    "    \n",
    "    null_freq.columns = ['source_degree', 'target_degree', 'edge_count', 'total_count', 'edge_probability']\n",
    "    \n",
    "    return null_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors_by_degree(predictions, actuals, source_degrees, target_degrees):\n",
    "    \"\"\"\n",
    "    Analyze prediction errors stratified by degree bins.\n",
    "    \"\"\"\n",
    "    # Define degree bins\n",
    "    degree_bins = [0, 1, 2, 5, 10, 20, 50, 100, 500, np.inf]\n",
    "    degree_labels = ['0', '1', '2-4', '5-9', '10-19', '20-49', '50-99', '100-499', '500+']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Bin degrees\n",
    "    source_bins = pd.cut(source_degrees, bins=degree_bins, labels=degree_labels)\n",
    "    target_bins = pd.cut(target_degrees, bins=degree_bins, labels=degree_labels)\n",
    "    \n",
    "    # Error metrics by source degree\n",
    "    for bin_label in degree_labels:\n",
    "        mask = source_bins == bin_label\n",
    "        if mask.sum() >= 10:\n",
    "            results.append({\n",
    "                'stratification': 'source_degree',\n",
    "                'bin': bin_label,\n",
    "                'n_samples': int(mask.sum()),\n",
    "                'mean_prediction': float(predictions[mask].mean()),\n",
    "                'mean_actual': float(actuals[mask].mean()),\n",
    "                'mae': float(np.abs(predictions[mask] - actuals[mask]).mean()),\n",
    "                'rmse': float(np.sqrt(((predictions[mask] - actuals[mask])**2).mean())),\n",
    "                'correlation': float(np.corrcoef(predictions[mask], actuals[mask])[0,1]) if mask.sum() > 1 else np.nan,\n",
    "                'mean_degree': float(source_degrees[mask].mean())\n",
    "            })\n",
    "    \n",
    "    # Error metrics by target degree\n",
    "    for bin_label in degree_labels:\n",
    "        mask = target_bins == bin_label\n",
    "        if mask.sum() >= 10:\n",
    "            results.append({\n",
    "                'stratification': 'target_degree',\n",
    "                'bin': bin_label,\n",
    "                'n_samples': int(mask.sum()),\n",
    "                'mean_prediction': float(predictions[mask].mean()),\n",
    "                'mean_actual': float(actuals[mask].mean()),\n",
    "                'mae': float(np.abs(predictions[mask] - actuals[mask]).mean()),\n",
    "                'rmse': float(np.sqrt(((predictions[mask] - actuals[mask])**2).mean())),\n",
    "                'correlation': float(np.corrcoef(predictions[mask], actuals[mask])[0,1]) if mask.sum() > 1 else np.nan,\n",
    "                'mean_degree': float(target_degrees[mask].mean())\n",
    "            })\n",
    "    \n",
    "    # Error metrics by degree product\n",
    "    degree_products = source_degrees * target_degrees\n",
    "    product_bins = pd.cut(degree_products, \n",
    "                          bins=[0, 1, 10, 100, 1000, 10000, 100000, np.inf],\n",
    "                          labels=['0-1', '2-10', '11-100', '101-1K', '1K-10K', '10K-100K', '100K+'])\n",
    "    \n",
    "    for bin_label in product_bins.unique():\n",
    "        if pd.notna(bin_label):\n",
    "            mask = product_bins == bin_label\n",
    "            if mask.sum() >= 10:\n",
    "                results.append({\n",
    "                    'stratification': 'degree_product',\n",
    "                    'bin': str(bin_label),\n",
    "                    'n_samples': int(mask.sum()),\n",
    "                    'mean_prediction': float(predictions[mask].mean()),\n",
    "                    'mean_actual': float(actuals[mask].mean()),\n",
    "                    'mae': float(np.abs(predictions[mask] - actuals[mask]).mean()),\n",
    "                    'rmse': float(np.sqrt(((predictions[mask] - actuals[mask])**2).mean())),\n",
    "                    'correlation': float(np.corrcoef(predictions[mask], actuals[mask])[0,1]) if mask.sum() > 1 else np.nan,\n",
    "                    'mean_product': float(degree_products[mask].mean())\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Null Models for All Edge Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = []\n",
    "\n",
    "for edge_type in edge_types_to_process:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training null models for {edge_type}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Load training data (perms 1-20)\n",
    "    print(f\"Loading training data from permutations {training_perm_range[0]}-{training_perm_range[1]-1}...\")\n",
    "    train_freq = load_null_edge_frequencies(\n",
    "        edge_type, \n",
    "        range(training_perm_range[0], training_perm_range[1])\n",
    "    )\n",
    "    \n",
    "    if len(train_freq) == 0:\n",
    "        print(f\"  ⚠ No training data found for {edge_type}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"  Training samples: {len(train_freq):,}\")\n",
    "    print(f\"  Source degree range: {train_freq['source_degree'].min()}-{train_freq['source_degree'].max()}\")\n",
    "    print(f\"  Target degree range: {train_freq['target_degree'].min()}-{train_freq['target_degree'].max()}\")\n",
    "    print(f\"  Mean edge probability: {train_freq['edge_probability'].mean():.4f}\")\n",
    "    \n",
    "    # Prepare features and targets\n",
    "    X_train = train_freq[['source_degree', 'target_degree']].values\n",
    "    y_train = train_freq['edge_probability'].values\n",
    "    \n",
    "    # Train Polynomial Logistic Regression\n",
    "    print(f\"\\nTraining Polynomial Logistic Regression...\")\n",
    "    poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "    \n",
    "    poly_model = Ridge(alpha=1.0, random_state=42)\n",
    "    poly_model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    print(f\"Training Random Forest...\")\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=10, \n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Save models\n",
    "    poly_model_file = results_dir / f'{edge_type}_poly_null.pkl'\n",
    "    poly_features_file = results_dir / f'{edge_type}_poly_features.pkl'\n",
    "    rf_model_file = results_dir / f'{edge_type}_rf_null.pkl'\n",
    "    \n",
    "    joblib.dump(poly_model, poly_model_file)\n",
    "    joblib.dump(poly_features, poly_features_file)\n",
    "    joblib.dump(rf_model, rf_model_file)\n",
    "    \n",
    "    print(f\"  ✓ Saved models:\")\n",
    "    print(f\"    - {poly_model_file.name}\")\n",
    "    print(f\"    - {poly_features_file.name}\")\n",
    "    print(f\"    - {rf_model_file.name}\")\n",
    "    \n",
    "    training_results.append({\n",
    "        'edge_type': edge_type,\n",
    "        'n_training_samples': len(train_freq),\n",
    "        'mean_edge_prob': train_freq['edge_probability'].mean(),\n",
    "        'poly_model_file': str(poly_model_file),\n",
    "        'rf_model_file': str(rf_model_file)\n",
    "    })\n",
    "\n",
    "training_df = pd.DataFrame(training_results)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Successfully trained models for {len(training_df)} edge types\")\n",
    "print(f\"Total model files: {len(training_df) * 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate on Held-Out Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results = []\n",
    "\n",
    "for edge_type in edge_types_to_process:\n",
    "    print(f\"\\nValidating {edge_type}...\")\n",
    "    \n",
    "    # Check if models exist\n",
    "    poly_model_file = results_dir / f'{edge_type}_poly_null.pkl'\n",
    "    poly_features_file = results_dir / f'{edge_type}_poly_features.pkl'\n",
    "    rf_model_file = results_dir / f'{edge_type}_rf_null.pkl'\n",
    "    \n",
    "    if not all([poly_model_file.exists(), rf_model_file.exists()]):\n",
    "        print(f\"  ⚠ Models not found, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Load validation data (perms 21-30)\n",
    "    val_freq = load_null_edge_frequencies(\n",
    "        edge_type,\n",
    "        range(validation_perm_range[0], validation_perm_range[1])\n",
    "    )\n",
    "    \n",
    "    if len(val_freq) == 0:\n",
    "        print(f\"  ⚠ No validation data found, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    X_val = val_freq[['source_degree', 'target_degree']].values\n",
    "    y_val = val_freq['edge_probability'].values\n",
    "    \n",
    "    # Load models\n",
    "    poly_model = joblib.load(poly_model_file)\n",
    "    poly_features = joblib.load(poly_features_file)\n",
    "    rf_model = joblib.load(rf_model_file)\n",
    "    \n",
    "    # Predict with Polynomial LogReg\n",
    "    X_val_poly = poly_features.transform(X_val)\n",
    "    y_pred_poly = poly_model.predict(X_val_poly)\n",
    "    y_pred_poly = np.clip(y_pred_poly, 0, 1)  # Ensure valid probabilities\n",
    "    \n",
    "    # Predict with Random Forest\n",
    "    y_pred_rf = rf_model.predict(X_val)\n",
    "    y_pred_rf = np.clip(y_pred_rf, 0, 1)\n",
    "    \n",
    "    # Evaluate Polynomial LogReg\n",
    "    corr_poly, _ = pearsonr(y_val, y_pred_poly)\n",
    "    mae_poly = np.abs(y_val - y_pred_poly).mean()\n",
    "    rmse_poly = np.sqrt(((y_val - y_pred_poly)**2).mean())\n",
    "    \n",
    "    # Evaluate Random Forest\n",
    "    corr_rf, _ = pearsonr(y_val, y_pred_rf)\n",
    "    mae_rf = np.abs(y_val - y_pred_rf).mean()\n",
    "    rmse_rf = np.sqrt(((y_val - y_pred_rf)**2).mean())\n",
    "    \n",
    "    print(f\"  Validation samples: {len(val_freq):,}\")\n",
    "    print(f\"  Polynomial LogReg: r={corr_poly:.4f}, MAE={mae_poly:.4f}, RMSE={rmse_poly:.4f}\")\n",
    "    print(f\"  Random Forest:     r={corr_rf:.4f}, MAE={mae_rf:.4f}, RMSE={rmse_rf:.4f}\")\n",
    "    \n",
    "    # Error analysis by degree (using RF predictions)\n",
    "    error_df = analyze_errors_by_degree(y_pred_rf, y_val, X_val[:, 0], X_val[:, 1])\n",
    "    error_df['edge_type'] = edge_type\n",
    "    \n",
    "    # Save error analysis\n",
    "    error_file = results_dir / f'{edge_type}_error_analysis.csv'\n",
    "    error_df.to_csv(error_file, index=False)\n",
    "    \n",
    "    validation_results.append({\n",
    "        'edge_type': edge_type,\n",
    "        'n_validation_samples': len(val_freq),\n",
    "        'poly_correlation': corr_poly,\n",
    "        'poly_mae': mae_poly,\n",
    "        'poly_rmse': rmse_poly,\n",
    "        'rf_correlation': corr_rf,\n",
    "        'rf_mae': mae_rf,\n",
    "        'rf_rmse': rmse_rf\n",
    "    })\n",
    "\n",
    "validation_df = pd.DataFrame(validation_results)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"VALIDATION COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nValidation Summary:\")\n",
    "print(f\"  Mean Poly correlation: {validation_df['poly_correlation'].mean():.4f}\")\n",
    "print(f\"  Mean RF correlation:   {validation_df['rf_correlation'].mean():.4f}\")\n",
    "print(f\"  Mean Poly RMSE:        {validation_df['poly_rmse'].mean():.4f}\")\n",
    "print(f\"  Mean RF RMSE:          {validation_df['rf_rmse'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation results\n",
    "validation_file = results_dir / 'validation_results.csv'\n",
    "validation_df.to_csv(validation_file, index=False)\n",
    "print(f\"Saved validation results to: {validation_file}\")\n",
    "\n",
    "# Save training summary\n",
    "training_file = results_dir / 'training_summary.csv'\n",
    "training_df.to_csv(training_file, index=False)\n",
    "print(f\"Saved training summary to: {training_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation performance comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Correlation comparison\n",
    "ax = axes[0]\n",
    "x = np.arange(len(validation_df))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, validation_df['poly_correlation'], width, label='Polynomial LogReg', alpha=0.7)\n",
    "ax.bar(x + width/2, validation_df['rf_correlation'], width, label='Random Forest', alpha=0.7)\n",
    "ax.set_xlabel('Edge Type', fontsize=12)\n",
    "ax.set_ylabel('Correlation', fontsize=12)\n",
    "ax.set_title('Validation Correlation by Edge Type', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(validation_df['edge_type'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.axhline(y=0.7, color='red', linestyle='--', alpha=0.5, label='Target (0.7)')\n",
    "\n",
    "# RMSE comparison\n",
    "ax = axes[1]\n",
    "ax.bar(x - width/2, validation_df['poly_rmse'], width, label='Polynomial LogReg', alpha=0.7)\n",
    "ax.bar(x + width/2, validation_df['rf_rmse'], width, label='Random Forest', alpha=0.7)\n",
    "ax.set_xlabel('Edge Type', fontsize=12)\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.set_title('Validation RMSE by Edge Type', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(validation_df['edge_type'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Scatter: Poly vs RF correlation\n",
    "ax = axes[2]\n",
    "ax.scatter(validation_df['poly_correlation'], validation_df['rf_correlation'], s=100, alpha=0.6)\n",
    "ax.plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
    "ax.set_xlabel('Polynomial LogReg Correlation', fontsize=12)\n",
    "ax.set_ylabel('Random Forest Correlation', fontsize=12)\n",
    "ax.set_title('Model Comparison', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "for idx, row in validation_df.iterrows():\n",
    "    ax.annotate(row['edge_type'], \n",
    "               (row['poly_correlation'], row['rf_correlation']),\n",
    "               fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'validation_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved validation performance plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NULL MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  Permutations: {training_perm_range[0]}-{training_perm_range[1]-1}\")\n",
    "print(f\"  Edge types: {len(training_df)}\")\n",
    "print(f\"  Models created: {len(training_df) * 2} (Poly + RF)\")\n",
    "\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  Permutations: {validation_perm_range[0]}-{validation_perm_range[1]-1}\")\n",
    "print(f\"  Edge types: {len(validation_df)}\")\n",
    "\n",
    "print(f\"\\nPerformance (held-out null networks):\")\n",
    "print(f\"  Polynomial LogReg:\")\n",
    "print(f\"    Mean correlation: {validation_df['poly_correlation'].mean():.4f} (±{validation_df['poly_correlation'].std():.4f})\")\n",
    "print(f\"    Mean RMSE:        {validation_df['poly_rmse'].mean():.4f} (±{validation_df['poly_rmse'].std():.4f})\")\n",
    "print(f\"  Random Forest:\")\n",
    "print(f\"    Mean correlation: {validation_df['rf_correlation'].mean():.4f} (±{validation_df['rf_correlation'].std():.4f})\")\n",
    "print(f\"    Mean RMSE:        {validation_df['rf_rmse'].mean():.4f} (±{validation_df['rf_rmse'].std():.4f})\")\n",
    "\n",
    "print(f\"\\nBest performing edge types (by RF correlation):\")\n",
    "top_5 = validation_df.nlargest(5, 'rf_correlation')[['edge_type', 'rf_correlation', 'rf_rmse']]\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"  {row['edge_type']}: r={row['rf_correlation']:.4f}, RMSE={row['rf_rmse']:.4f}\")\n",
    "\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  Model files: {len(list(results_dir.glob('*_null.pkl')))} + {len(list(results_dir.glob('*_features.pkl')))}\")\n",
    "print(f\"  Validation results: {validation_file.name}\")\n",
    "print(f\"  Training summary: {training_file.name}\")\n",
    "print(f\"  Error analysis files: {len(list(results_dir.glob('*_error_analysis.csv')))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
