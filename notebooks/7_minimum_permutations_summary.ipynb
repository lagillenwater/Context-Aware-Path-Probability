{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Permutations Summary Across Edge Types\n",
    "\n",
    "This notebook aggregates and analyzes the results from **Notebook 6** (minimum permutations analysis for ML models) across all 24 edge types.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Summarize N_min (minimum permutations) for each model across all edge types\n",
    "- Identify which models are most data-efficient\n",
    "- Analyze relationship between graph characteristics and N_min\n",
    "- Provide recommendations for choosing N based on graph properties\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Load results from all edge types\n",
    "2. Aggregate N_min by model and edge type\n",
    "3. Analyze convergence patterns\n",
    "4. Correlate N_min with graph characteristics (density, size, degree)\n",
    "5. Generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import scipy.sparse as sp\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "repo_dir = Path.cwd().parent\n",
    "data_dir = repo_dir / 'data'\n",
    "results_dir = repo_dir / 'results' / 'minimum_permutations_ml'\n",
    "summary_dir = repo_dir / 'results' / 'minimum_permutations_ml_summary'\n",
    "summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Repository directory: {repo_dir}\")\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "print(f\"Summary output directory: {summary_dir}\")\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Discover and Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all edge type result directories\n",
    "result_dirs = [d for d in results_dir.iterdir() if d.is_dir() and d.name.endswith('_results')]\n",
    "edge_types = [d.name.replace('_results', '') for d in result_dirs]\n",
    "\n",
    "print(f\"Found results for {len(edge_types)} edge types\")\n",
    "\n",
    "# Load all summaries\n",
    "all_summaries = {}\n",
    "all_convergence_data = {}\n",
    "successful_loads = 0\n",
    "failed_loads = []\n",
    "\n",
    "for edge_type in edge_types:\n",
    "    summary_file = results_dir / f'{edge_type}_results' / f'{edge_type}_summary.json'\n",
    "    convergence_file = results_dir / f'{edge_type}_results' / f'{edge_type}_convergence_data.csv'\n",
    "    \n",
    "    if summary_file.exists():\n",
    "        with open(summary_file, 'r') as f:\n",
    "            all_summaries[edge_type] = json.load(f)\n",
    "        successful_loads += 1\n",
    "    else:\n",
    "        failed_loads.append(edge_type)\n",
    "    \n",
    "    if convergence_file.exists():\n",
    "        all_convergence_data[edge_type] = pd.read_csv(convergence_file)\n",
    "\n",
    "print(f\"Successfully loaded {successful_loads} summaries\")\n",
    "if failed_loads:\n",
    "    print(f\"Failed to load: {failed_loads}\")\n",
    "\n",
    "# Display sample\n",
    "if all_summaries:\n",
    "    sample_edge = list(all_summaries.keys())[0]\n",
    "    print(f\"\\nSample summary ({sample_edge}):\")\n",
    "    print(f\"  Target metric: {all_summaries[sample_edge]['target_metric']}\")\n",
    "    print(f\"  Models: {list(all_summaries[sample_edge]['models'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Graph Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_characteristics(edge_type: str) -> Dict:\n",
    "    \"\"\"Extract graph characteristics from edge matrix.\"\"\"\n",
    "    edge_file = data_dir / 'permutations' / '000.hetmat' / 'edges' / f\"{edge_type}.sparse.npz\"\n",
    "    \n",
    "    if not edge_file.exists():\n",
    "        return None\n",
    "    \n",
    "    # Load edge matrix\n",
    "    edge_matrix = sp.load_npz(edge_file)\n",
    "    n_sources, n_targets = edge_matrix.shape\n",
    "    n_edges = edge_matrix.nnz\n",
    "    \n",
    "    # Calculate characteristics\n",
    "    density = n_edges / (n_sources * n_targets)\n",
    "    source_degrees = np.array(edge_matrix.sum(axis=1)).flatten()\n",
    "    target_degrees = np.array(edge_matrix.sum(axis=0)).flatten()\n",
    "    \n",
    "    # Filter zero degrees\n",
    "    source_degrees_nz = source_degrees[source_degrees > 0]\n",
    "    target_degrees_nz = target_degrees[target_degrees > 0]\n",
    "    \n",
    "    return {\n",
    "        'edge_type': edge_type,\n",
    "        'n_sources': n_sources,\n",
    "        'n_targets': n_targets,\n",
    "        'n_edges': n_edges,\n",
    "        'density': density,\n",
    "        'mean_source_degree': source_degrees_nz.mean() if len(source_degrees_nz) > 0 else 0,\n",
    "        'mean_target_degree': target_degrees_nz.mean() if len(target_degrees_nz) > 0 else 0,\n",
    "        'max_source_degree': source_degrees.max(),\n",
    "        'max_target_degree': target_degrees.max(),\n",
    "        'n_sources_nz': len(source_degrees_nz),\n",
    "        'n_targets_nz': len(target_degrees_nz)\n",
    "    }\n",
    "\n",
    "# Load graph characteristics\n",
    "graph_chars = []\n",
    "for edge_type in all_summaries.keys():\n",
    "    chars = get_graph_characteristics(edge_type)\n",
    "    if chars is not None:\n",
    "        graph_chars.append(chars)\n",
    "\n",
    "graph_chars_df = pd.DataFrame(graph_chars)\n",
    "print(f\"\\nLoaded graph characteristics for {len(graph_chars_df)} edge types\")\n",
    "print(f\"Density range: {graph_chars_df['density'].min():.6f} - {graph_chars_df['density'].max():.6f}\")\n",
    "print(f\"Edge count range: {graph_chars_df['n_edges'].min()} - {graph_chars_df['n_edges'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aggregate N_min by Model and Edge Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create N_min matrix (edge_types × models)\n",
    "n_min_data = []\n",
    "\n",
    "for edge_type, summary in all_summaries.items():\n",
    "    entry = {'edge_type': edge_type}\n",
    "    \n",
    "    for model_name, model_data in summary['models'].items():\n",
    "        entry[f'{model_name}_N_min'] = model_data['N_min']\n",
    "        entry[f'{model_name}_achieved'] = model_data['achieved_value']\n",
    "        entry[f'{model_name}_target_met'] = model_data['target_met']\n",
    "    \n",
    "    n_min_data.append(entry)\n",
    "\n",
    "n_min_df = pd.DataFrame(n_min_data)\n",
    "\n",
    "# Merge with graph characteristics\n",
    "n_min_df = n_min_df.merge(graph_chars_df, on='edge_type', how='left')\n",
    "\n",
    "# Add density category\n",
    "n_min_df['density_category'] = pd.cut(\n",
    "    n_min_df['density'],\n",
    "    bins=[0, 0.01, 0.03, 0.05, 1.0],\n",
    "    labels=['Very Sparse (<1%)', 'Sparse (1-3%)', 'Medium (3-5%)', 'Dense (>5%)']\n",
    ")\n",
    "\n",
    "print(f\"\\nN_min data shape: {n_min_df.shape}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(n_min_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. N_min Statistics by Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model names\n",
    "model_names = [col.replace('_N_min', '') for col in n_min_df.columns if col.endswith('_N_min')]\n",
    "\n",
    "print(\"N_min Statistics by Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name in model_names:\n",
    "    n_min_col = f'{model_name}_N_min'\n",
    "    n_mins = n_min_df[n_min_col]\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Mean N_min: {n_mins.mean():.1f}\")\n",
    "    print(f\"  Median N_min: {n_mins.median():.0f}\")\n",
    "    print(f\"  Min N_min: {n_mins.min()}\")\n",
    "    print(f\"  Max N_min: {n_mins.max()}\")\n",
    "    print(f\"  Std N_min: {n_mins.std():.1f}\")\n",
    "\n",
    "# Overall most data-efficient model\n",
    "model_means = {m: n_min_df[f'{m}_N_min'].mean() for m in model_names}\n",
    "best_model = min(model_means, key=model_means.get)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Most data-efficient model overall: {best_model} (mean N_min = {model_means[best_model]:.1f})\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. N_min heatmap (edge types × models)\n",
    "fig, ax = plt.subplots(figsize=(12, 16))\n",
    "\n",
    "# Prepare data for heatmap\n",
    "heatmap_data = n_min_df.set_index('edge_type')[[f'{m}_N_min' for m in model_names]]\n",
    "heatmap_data.columns = model_names\n",
    "\n",
    "# Sort by mean N_min\n",
    "heatmap_data = heatmap_data.loc[heatmap_data.mean(axis=1).sort_values().index]\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    annot=True,\n",
    "    fmt='.0f',\n",
    "    cmap='RdYlGn_r',\n",
    "    ax=ax,\n",
    "    cbar_kws={'label': 'N_min (Minimum Permutations)'}\n",
    ")\n",
    "\n",
    "ax.set_title('Minimum Permutations by Edge Type and Model', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('Edge Type', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(summary_dir / 'N_min_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved N_min heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. N_min distribution by model\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Prepare data for box plot\n",
    "box_data = [n_min_df[f'{m}_N_min'] for m in model_names]\n",
    "\n",
    "bp = ax.boxplot(box_data, labels=model_names, patch_artist=True)\n",
    "\n",
    "# Color boxes\n",
    "colors = sns.color_palette('Set2', len(model_names))\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax.set_ylabel('N_min (Minimum Permutations)', fontsize=12)\n",
    "ax.set_title('N_min Distribution by Model', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(summary_dir / 'N_min_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved N_min distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. N_min vs Graph Density\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, model_name in enumerate(model_names):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    n_min_col = f'{model_name}_N_min'\n",
    "    \n",
    "    ax.scatter(n_min_df['density'], n_min_df[n_min_col], alpha=0.6, s=100)\n",
    "    \n",
    "    # Add edge type labels for outliers\n",
    "    for _, row in n_min_df.iterrows():\n",
    "        if row[n_min_col] > n_min_df[n_min_col].quantile(0.75):\n",
    "            ax.annotate(row['edge_type'], (row['density'], row[n_min_col]), \n",
    "                       fontsize=8, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Graph Density', fontsize=12)\n",
    "    ax.set_ylabel('N_min', fontsize=12)\n",
    "    ax.set_title(f'{model_name}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(summary_dir / 'N_min_vs_density.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved N_min vs density plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. N_min by density category\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Prepare data for grouped bar chart\n",
    "density_groups = []\n",
    "for cat in n_min_df['density_category'].dropna().unique():\n",
    "    cat_data = n_min_df[n_min_df['density_category'] == cat]\n",
    "    for model_name in model_names:\n",
    "        density_groups.append({\n",
    "            'Density Category': cat,\n",
    "            'Model': model_name,\n",
    "            'Mean N_min': cat_data[f'{model_name}_N_min'].mean()\n",
    "        })\n",
    "\n",
    "density_df = pd.DataFrame(density_groups)\n",
    "pivot = density_df.pivot(index='Density Category', columns='Model', values='Mean N_min')\n",
    "\n",
    "pivot.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_ylabel('Mean N_min', fontsize=12)\n",
    "ax.set_title('Average N_min by Graph Density Category', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(summary_dir / 'N_min_by_density_category.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved N_min by density category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model comparison: Which is most data-efficient?\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "model_means = [n_min_df[f'{m}_N_min'].mean() for m in model_names]\n",
    "model_stds = [n_min_df[f'{m}_N_min'].std() for m in model_names]\n",
    "\n",
    "bars = ax.bar(range(len(model_names)), model_means, yerr=model_stds, \n",
    "              color=sns.color_palette('Set2', len(model_names)), \n",
    "              alpha=0.7, edgecolor='black', capsize=5)\n",
    "\n",
    "ax.set_xticks(range(len(model_names)))\n",
    "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax.set_ylabel('Mean N_min Across All Edge Types', fontsize=12)\n",
    "ax.set_title('Data Efficiency Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, mean, std) in enumerate(zip(bars, model_means, model_stds)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.5,\n",
    "            f'{mean:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(summary_dir / 'model_efficiency_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved model efficiency comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full N_min data\n",
    "n_min_df.to_csv(summary_dir / 'N_min_by_edge_type.csv', index=False)\n",
    "print(f\"Saved N_min data: {summary_dir / 'N_min_by_edge_type.csv'}\")\n",
    "\n",
    "# Save model statistics\n",
    "model_stats = []\n",
    "for model_name in model_names:\n",
    "    n_min_col = f'{model_name}_N_min'\n",
    "    model_stats.append({\n",
    "        'Model': model_name,\n",
    "        'Mean_N_min': n_min_df[n_min_col].mean(),\n",
    "        'Median_N_min': n_min_df[n_min_col].median(),\n",
    "        'Std_N_min': n_min_df[n_min_col].std(),\n",
    "        'Min_N_min': n_min_df[n_min_col].min(),\n",
    "        'Max_N_min': n_min_df[n_min_col].max()\n",
    "    })\n",
    "\n",
    "model_stats_df = pd.DataFrame(model_stats)\n",
    "model_stats_df.to_csv(summary_dir / 'model_statistics.csv', index=False)\n",
    "print(f\"Saved model statistics: {summary_dir / 'model_statistics.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MINIMUM PERMUTATIONS RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall champion\n",
    "best_model_overall = model_stats_df.loc[model_stats_df['Mean_N_min'].idxmin(), 'Model']\n",
    "best_mean = model_stats_df.loc[model_stats_df['Mean_N_min'].idxmin(), 'Mean_N_min']\n",
    "print(f\"\\n1. MOST DATA-EFFICIENT MODEL OVERALL: {best_model_overall}\")\n",
    "print(f\"   Average N_min across all edge types: {best_mean:.1f}\")\n",
    "\n",
    "# Best by density category\n",
    "print(\"\\n2. RECOMMENDATIONS BY GRAPH DENSITY:\")\n",
    "for cat in ['Very Sparse (<1%)', 'Sparse (1-3%)', 'Medium (3-5%)', 'Dense (>5%)']:\n",
    "    cat_data = n_min_df[n_min_df['density_category'] == cat]\n",
    "    if len(cat_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    model_means_cat = {m: cat_data[f'{m}_N_min'].mean() for m in model_names}\n",
    "    best_model_cat = min(model_means_cat, key=model_means_cat.get)\n",
    "    best_mean_cat = model_means_cat[best_model_cat]\n",
    "    \n",
    "    print(f\"   {cat}: {best_model_cat} (avg N_min = {best_mean_cat:.1f})\")\n",
    "\n",
    "# Rule of thumb\n",
    "print(\"\\n3. GENERAL GUIDELINES:\")\n",
    "overall_median = n_min_df[[f'{m}_N_min' for m in model_names]].median().median()\n",
    "print(f\"   Median N_min across all models and edge types: {overall_median:.0f}\")\n",
    "print(f\"   Conservative recommendation: Use N ≥ {int(np.ceil(overall_median * 1.5))} for new graphs\")\n",
    "\n",
    "# Correlation with density\n",
    "print(\"\\n4. RELATIONSHIP WITH GRAPH DENSITY:\")\n",
    "for model_name in model_names:\n",
    "    corr = n_min_df['density'].corr(n_min_df[f'{model_name}_N_min'])\n",
    "    print(f\"   {model_name}: correlation = {corr:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAll results saved to: {summary_dir}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "for file in sorted(summary_dir.glob('*')):\n",
    "    print(f\"  - {file.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
