{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formula Testing: Compare Original, Extended, and Polynomial\n",
    "\n",
    "This notebook tests the improvements to the learned analytical formula on **CtD** (sparse) and **AeG** (dense) edge types.\n",
    "\n",
    "## Formulas Tested\n",
    "\n",
    "### 1. Original (9 parameters)\n",
    "```\n",
    "P = α × (u^β × v^γ) / (δ + ε×m + ζ×(u×v)^η + θ×density^κ)\n",
    "```\n",
    "\n",
    "### 2. Extended (11 parameters)\n",
    "```\n",
    "P = α × (u^β × v^γ) / (δ + ε×m + ζ×(u×v)^η + θ×density^κ + λ×log(u+1) + μ×log(v+1))\n",
    "```\n",
    "\n",
    "### 3. Polynomial (9 parameters)\n",
    "```\n",
    "P = (α×u×v + β×u + γ×v + δ) / (ε×m + ζ×u×v + η×(u+v) + θ + ι×density)\n",
    "```\n",
    "\n",
    "## Improvements Tested\n",
    "- Multi-start optimization (10 random initializations)\n",
    "- Configurable L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "repo_dir = Path.cwd().parent\n",
    "src_dir = repo_dir / 'src'\n",
    "data_dir = repo_dir / 'data'\n",
    "results_dir = repo_dir / 'results'\n",
    "\n",
    "sys.path.append(str(src_dir))\n",
    "\n",
    "from learned_analytical import LearnedAnalyticalFormula\n",
    "\n",
    "print(\"Modules imported successfully!\")\n",
    "print(f\"Repository: {repo_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test edge types\n",
    "test_edge_types = ['CtD', 'AeG']  # Sparse and dense\n",
    "\n",
    "# Test N values (smaller for faster testing)\n",
    "test_N_values = [5, 10, 20]\n",
    "\n",
    "# Formulas to test\n",
    "formula_types = ['original', 'extended', 'polynomial']\n",
    "\n",
    "# Configuration\n",
    "n_random_starts = 10\n",
    "regularization_lambda = 0.001\n",
    "convergence_threshold = 0.02\n",
    "target_metric = 'correlation'\n",
    "min_metric_value = 0.95\n",
    "\n",
    "print(f\"Testing on edge types: {test_edge_types}\")\n",
    "print(f\"Testing N values: {test_N_values}\")\n",
    "print(f\"Testing formulas: {formula_types}\")\n",
    "print(f\"Multi-start: {n_random_starts} random initializations\")\n",
    "print(f\"L2 regularization: λ = {regularization_lambda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for results\n",
    "all_results = []\n",
    "\n",
    "for edge_type in test_edge_types:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TESTING {edge_type}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    for formula_type in formula_types:\n",
    "        print(f\"\\n{'-'*60}\")\n",
    "        print(f\"Formula: {formula_type.upper()}\")\n",
    "        print(f\"{'-'*60}\\n\")\n",
    "\n",
    "        # Initialize learner\n",
    "        learner = LearnedAnalyticalFormula(\n",
    "            n_random_starts=n_random_starts,\n",
    "            regularization_lambda=regularization_lambda,\n",
    "            formula_type=formula_type\n",
    "        )\n",
    "\n",
    "        # Run with limited N values for testing\n",
    "        try:\n",
    "            results = learner.find_minimum_permutations(\n",
    "                graph_name=edge_type,\n",
    "                data_dir=data_dir,\n",
    "                results_dir=results_dir,\n",
    "                N_candidates=test_N_values,\n",
    "                convergence_threshold=convergence_threshold,\n",
    "                target_metric=target_metric,\n",
    "                min_metric_value=min_metric_value\n",
    "            )\n",
    "\n",
    "            # Store summary\n",
    "            all_results.append({\n",
    "                'edge_type': edge_type,\n",
    "                'formula': formula_type,\n",
    "                'N_min': results['N_min'],\n",
    "                'final_correlation': results['final_metrics']['correlation'],\n",
    "                'final_mae': results['final_metrics']['mae'],\n",
    "                'baseline_correlation': results['baseline_metrics']['correlation'],\n",
    "                'baseline_mae': results['baseline_metrics']['mae'],\n",
    "                'improvement_correlation': results['final_metrics']['correlation'] - results['baseline_metrics']['correlation'],\n",
    "                'n_params': len(learner.params)\n",
    "            })\n",
    "\n",
    "            print(f\"\\n✓ SUCCESS\")\n",
    "            print(f\"  N_min: {results['N_min']}\")\n",
    "            print(f\"  Final correlation: {results['final_metrics']['correlation']:.4f}\")\n",
    "            print(f\"  Baseline correlation: {results['baseline_metrics']['correlation']:.4f}\")\n",
    "            print(f\"  Improvement: {results['final_metrics']['correlation'] - results['baseline_metrics']['correlation']:+.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ FAILED: {e}\")\n",
    "            all_results.append({\n",
    "                'edge_type': edge_type,\n",
    "                'formula': formula_type,\n",
    "                'N_min': None,\n",
    "                'final_correlation': None,\n",
    "                'final_mae': None,\n",
    "                'baseline_correlation': None,\n",
    "                'baseline_mae': None,\n",
    "                'improvement_correlation': None,\n",
    "                'n_params': None\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ALL TESTS COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for edge_type in test_edge_types:\n",
    "    print(f\"\\n{edge_type}:\")\n",
    "    edge_results = results_df[results_df['edge_type'] == edge_type]\n",
    "\n",
    "    for _, row in edge_results.iterrows():\n",
    "        if row['final_correlation'] is not None:\n",
    "            print(f\"  {row['formula']:12s}: r={row['final_correlation']:.4f} (baseline={row['baseline_correlation']:.4f}, Δ={row['improvement_correlation']:+.4f})\")\n",
    "        else:\n",
    "            print(f\"  {row['formula']:12s}: FAILED\")\n",
    "\n",
    "# Display full table\n",
    "print(\"\\nFull Results Table:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Formula Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Correlation comparison\n",
    "for edge_type, ax in zip(test_edge_types, axes):\n",
    "    edge_results = results_df[results_df['edge_type'] == edge_type]\n",
    "\n",
    "    formulas = edge_results['formula'].values\n",
    "    final_corrs = edge_results['final_correlation'].values\n",
    "    baseline_corrs = edge_results['baseline_correlation'].values\n",
    "\n",
    "    x = np.arange(len(formulas))\n",
    "    width = 0.35\n",
    "\n",
    "    ax.bar(x - width/2, baseline_corrs, width, label='Current Analytical', alpha=0.7, color='orange')\n",
    "    ax.bar(x + width/2, final_corrs, width, label='Learned Formula', alpha=0.7, color='green')\n",
    "\n",
    "    ax.set_xlabel('Formula Type', fontsize=12)\n",
    "    ax.set_ylabel('Correlation with Empirical', fontsize=12)\n",
    "    ax.set_title(f'{edge_type} - Correlation Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(formulas)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Add value labels\n",
    "    for i, (b, f) in enumerate(zip(baseline_corrs, final_corrs)):\n",
    "        if b is not None:\n",
    "            ax.text(i - width/2, b + 0.01, f'{b:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "        if f is not None:\n",
    "            ax.text(i + width/2, f + 0.01, f'{f:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(repo_dir / 'results' / 'formula_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved comparison plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best formula for each edge type\n",
    "for edge_type in test_edge_types:\n",
    "    edge_results = results_df[results_df['edge_type'] == edge_type]\n",
    "    best_formula = edge_results.loc[edge_results['final_correlation'].idxmax(), 'formula']\n",
    "    best_corr = edge_results['final_correlation'].max()\n",
    "    baseline_corr = edge_results.loc[edge_results['formula'] == best_formula, 'baseline_correlation'].values[0]\n",
    "    improvement = best_corr - baseline_corr\n",
    "\n",
    "    print(f\"\\n{edge_type}:\")\n",
    "    print(f\"  Best formula: {best_formula.upper()}\")\n",
    "    print(f\"  Correlation: {best_corr:.4f} (baseline: {baseline_corr:.4f})\")\n",
    "    print(f\"  Improvement: {improvement:+.4f} ({improvement/baseline_corr*100:+.1f}%)\")\n",
    "\n",
    "    if improvement > 0.01:\n",
    "        print(f\"  ✓ SIGNIFICANT IMPROVEMENT (> 1%)\")\n",
    "    elif improvement > 0:\n",
    "        print(f\"  → Modest improvement\")\n",
    "    else:\n",
    "        print(f\"  ✗ No improvement\")\n",
    "\n",
    "# Overall best formula\n",
    "avg_by_formula = results_df.groupby('formula')['improvement_correlation'].mean()\n",
    "overall_best = avg_by_formula.idxmax()\n",
    "avg_improvement = avg_by_formula.max()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"OVERALL BEST FORMULA: {overall_best.upper()}\")\n",
    "print(f\"Average improvement: {avg_improvement:+.4f}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(repo_dir / 'results' / 'formula_test_results.csv', index=False)\n",
    "print(f\"\\nResults saved to: {repo_dir / 'results' / 'formula_test_results.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
