{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc70c3ac",
   "metadata": {},
   "source": [
    "# Edge Prediction for Heterogeneous Networks\n",
    "\n",
    "## Single Permutation Analysis with Neural Networks and Baseline Models\n",
    "\n",
    "This notebook performs comprehensive edge prediction analysis on a single permutation of a heterogeneous network. It trains and evaluates multiple machine learning models to predict the existence of edges between nodes based on network topology features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f1552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries and functions\n",
    "import sys\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Additional imports for neural network training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Other utility imports\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "# Add src directory to path\n",
    "repo_dir = Path().absolute().parent\n",
    "src_dir = repo_dir / 'src'\n",
    "sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Import sampling functions\n",
    "from sampling import (\n",
    "    stratified_positive_sampling,\n",
    "    representative_negative_sampling, \n",
    "    create_representative_dataset\n",
    ")\n",
    "\n",
    "# Import enhanced experiment functions  \n",
    "from enhanced_experiments import (\n",
    "    run_enhanced_experiment,\n",
    "    analyze_enhanced_experiment_results,\n",
    "    calculate_prediction_stability\n",
    ")\n",
    "\n",
    "# Import data processing functions\n",
    "from data_processing import load_permutation_data, prepare_edge_prediction_data\n",
    "import data_processing\n",
    "importlib.reload(data_processing)\n",
    "\n",
    "# Import models\n",
    "from models import EdgePredictionNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e305628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using permutations subdirectory: permutations\n",
      "Edge type: AeG (Anatomy -> Gene)\n",
      "No specific permutation specified - will use first available\n"
     ]
    }
   ],
   "source": [
    "# Parameters for papermill\n",
    "# Default parameter values - can be overridden by papermill\n",
    "permutations_subdirectory = \"permutations\"  # Default: use 'permutations' (local generated)\n",
    "permutation_name = None  # Specific permutation to process (e.g., \"000\", \"001\", etc.)\n",
    "output_dir = \"models\"  # Directory to save trained models\n",
    "\n",
    "# Edge and node type parameters for flexible relationship modeling\n",
    "edge_type = \"AeG\"  # Edge type to model (e.g., \"AeG\", \"CbG\", \"DaG\", \"GiG\", etc.)\n",
    "source_node_type = \"Anatomy\"  # Source node type (e.g., \"Anatomy\", \"Compound\", \"Disease\", \"Gene\")\n",
    "target_node_type = \"Gene\"  # Target node type (e.g., \"Gene\", \"Anatomy\", \"Disease\", \"Compound\")\n",
    "\n",
    "# Validation\n",
    "if not isinstance(permutations_subdirectory, str):\n",
    "    raise ValueError(f\"permutations_subdirectory must be a string, got: {permutations_subdirectory}\")\n",
    "\n",
    "if permutation_name is not None and not isinstance(permutation_name, str):\n",
    "    raise ValueError(f\"permutation_name must be a string or None, got: {permutation_name}\")\n",
    "\n",
    "if not isinstance(edge_type, str):\n",
    "    raise ValueError(f\"edge_type must be a string, got: {edge_type}\")\n",
    "\n",
    "if not isinstance(source_node_type, str):\n",
    "    raise ValueError(f\"source_node_type must be a string, got: {source_node_type}\")\n",
    "\n",
    "if not isinstance(target_node_type, str):\n",
    "    raise ValueError(f\"target_node_type must be a string, got: {target_node_type}\")\n",
    "\n",
    "print(f\"Using permutations subdirectory: {permutations_subdirectory}\")\n",
    "print(f\"Edge type: {edge_type} ({source_node_type} -> {target_node_type})\")\n",
    "if permutation_name:\n",
    "    print(f\"Processing single permutation: {permutation_name}\")\n",
    "else:\n",
    "    print(\"No specific permutation specified - will use first available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713493a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository directory: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability\n",
      "Data directory: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data\n",
      "Permutations directory: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations\n",
      "Models output directory: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/models\n",
      "Available permutations: 2 total\n",
      "Using first available permutation: 001.hetmat\n"
     ]
    }
   ],
   "source": [
    "# Set up paths for data access using parameterized directory\n",
    "repo_dir = pathlib.Path().cwd().parent\n",
    "data_dir = repo_dir / \"data\"\n",
    "output_models_dir = repo_dir / output_dir\n",
    "\n",
    "# Use the parameterized permutations subdirectory\n",
    "if \"/\" in permutations_subdirectory:\n",
    "    permutations_dir = data_dir / permutations_subdirectory\n",
    "elif permutations_subdirectory == \"permutations\":\n",
    "    permutations_dir = data_dir / \"permutations\"\n",
    "else:\n",
    "    permutations_dir = data_dir / \"permutations\" / permutations_subdirectory\n",
    "\n",
    "print(f\"Repository directory: {repo_dir}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Permutations directory: {permutations_dir}\")\n",
    "print(f\"Models output directory: {output_models_dir}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# List available permutations\n",
    "if permutations_dir.exists():\n",
    "    available_permutations = [p.name for p in permutations_dir.iterdir() if p.is_dir()]\n",
    "    print(f\"Available permutations: {len(available_permutations)} total\")\n",
    "    \n",
    "    # Select specific permutation or first available\n",
    "    if permutation_name:\n",
    "        if permutation_name in available_permutations:\n",
    "            selected_permutation = permutation_name\n",
    "            print(f\"Selected permutation: {selected_permutation}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Permutation '{permutation_name}' not found. Available: {available_permutations[:5]}...\")\n",
    "    else:\n",
    "        if available_permutations:\n",
    "            selected_permutation = available_permutations[0]\n",
    "            print(f\"Using first available permutation: {selected_permutation}\")\n",
    "        else:\n",
    "            raise ValueError(\"No permutations found!\")\n",
    "else:\n",
    "    raise ValueError(f\"Permutations directory not found: {permutations_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8abdc326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading permutation: 001.hetmat\n",
      "Edge type: AeG (Anatomy -> Gene)\n",
      "Loading data from permutation: 001.hetmat\n",
      "Permutation path: /Users/lucas/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/data/permutations/001.hetmat\n",
      "Edge type: AeG (Anatomy -> Gene)\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Loaded Anatomy nodes: 402 nodes\n",
      "Anatomy columns: ['position', 'identifier', 'name']\n",
      "Loaded Gene nodes: 20945 nodes\n",
      "Gene columns: ['position', 'identifier', 'name']\n",
      "Successfully loaded permutation: 001.hetmat\n",
      "Permutation 001.hetmat data summary:\n",
      "  AeG edges matrix shape: (402, 20945)\n",
      "  Number of edges: 526407\n",
      "  Anatomy nodes: 402\n",
      "  Gene nodes: 20945\n",
      "  Matrix density: 0.062519\n"
     ]
    }
   ],
   "source": [
    "# Load data from the selected permutation\n",
    "print(f\"Loading permutation: {selected_permutation}\")\n",
    "print(f\"Edge type: {edge_type} ({source_node_type} -> {target_node_type})\")\n",
    "\n",
    "perm_data = load_permutation_data(\n",
    "    selected_permutation, \n",
    "    permutations_dir,\n",
    "    edge_type=edge_type,\n",
    "    source_node_type=source_node_type,\n",
    "    target_node_type=target_node_type\n",
    ")\n",
    "\n",
    "if not perm_data:\n",
    "    raise ValueError(f\"Failed to load permutation data for: {selected_permutation}\")\n",
    "\n",
    "print(f\"Successfully loaded permutation: {selected_permutation}\")\n",
    "\n",
    "# Extract data components using new parameterized keys\n",
    "edges = perm_data[\"edges\"]\n",
    "source_nodes = perm_data[\"source_nodes\"]\n",
    "target_nodes = perm_data[\"target_nodes\"]\n",
    "\n",
    "# Also extract with legacy names for backwards compatibility\n",
    "aeg_edges = perm_data[\"aeg_edges\"]  # Will be the same as edges\n",
    "anatomy_nodes = perm_data[\"anatomy_nodes\"]  # Will be the same as source_nodes\n",
    "gene_nodes = perm_data[\"gene_nodes\"]  # Will be the same as target_nodes\n",
    "\n",
    "print(f\"Permutation {selected_permutation} data summary:\")\n",
    "print(f\"  {edge_type} edges matrix shape: {edges.shape}\")\n",
    "print(f\"  Number of edges: {edges.nnz}\")\n",
    "print(f\"  {source_node_type} nodes: {len(source_nodes)}\")\n",
    "print(f\"  {target_node_type} nodes: {len(target_nodes)}\")\n",
    "print(f\"  Matrix density: {edges.nnz / (edges.shape[0] * edges.shape[1]):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a11ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Enhanced Experiment Run 1: Sample size 526407\n",
      "\n",
      "Creating representative dataset: 526407 positive + 526407 negative edges\n",
      "Positive method: stratified, Negative method: degree_matched\n",
      "Stratified sampling: Found 25 degree-based strata\n",
      "Sampled 526407 positive edges using stratified sampling\n",
      "\n",
      "Generating 526407 negative edges using degree_matched method...\n",
      "Positive edge degree stats - Source: 8702.6±3478.9\n",
      "Positive edge degree stats - Target: 41.8±17.1\n",
      "Using fast batch sampling approach...\n",
      "Generated 34133 negative edges (success rate: 0.341)\n",
      "\n",
      "Dataset created successfully:\n",
      "  Total samples: 560540\n",
      "  Positive: 526407, Negative: 34133\n",
      "  Feature correlation: -0.274\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run enhanced experiment\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_enhanced_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegrees_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdegrees_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/src/enhanced_experiments.py:231\u001b[0m, in \u001b[0;36mrun_enhanced_experiment\u001b[0;34m(sample_size, run_id, edges, degrees_dict, verbose)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Enhanced Neural Network\u001b[39;00m\n\u001b[1;32m    230\u001b[0m nn_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 231\u001b[0m nn_result \u001b[38;5;241m=\u001b[39m train_enhanced_neural_network(X_train, y_train, X_test, y_test, sample_size, run_id)\n\u001b[1;32m    232\u001b[0m nn_training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m nn_start_time\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Standard models for comparison\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/Context-Aware-Path-Probability/src/enhanced_experiments.py:146\u001b[0m, in \u001b[0;36mtrain_enhanced_neural_network\u001b[0;34m(X_train, y_train, X_test, y_test, sample_size, run_id)\u001b[0m\n\u001b[1;32m    144\u001b[0m train_outputs \u001b[38;5;241m=\u001b[39m model(X_train_sub)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    145\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m criterion(train_outputs, y_train_sub)\n\u001b[0;32m--> 146\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/CAPP/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/CAPP/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/CAPP/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare degrees dictionary for run_enhanced_experiment\n",
    "edges_coo = edges.tocoo()\n",
    "source_degrees = edges_coo.sum(axis=1).A1\n",
    "target_degrees = edges_coo.sum(axis=0).A1\n",
    "degrees_dict = {'source': source_degrees, 'target': target_degrees}\n",
    "\n",
    "# Use all available positive edges (or as many as possible)\n",
    "sample_size = edges_coo.nnz \n",
    "run_id = 0\n",
    "\n",
    "# Run enhanced experiment\n",
    "results = run_enhanced_experiment(\n",
    "    sample_size=sample_size,\n",
    "    run_id=run_id,\n",
    "    edges=edges,\n",
    "    degrees_dict=degrees_dict,\n",
    "    verbose=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAPP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
