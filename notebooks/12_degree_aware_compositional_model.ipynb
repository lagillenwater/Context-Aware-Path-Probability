{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree-Aware Compositional Model\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "1. **Does degree stratification improve compositional model fit?**\n",
    "2. **How much of the conditional structure is explained by degree heterogeneity alone?**\n",
    "3. **Can degree-aware priors reduce PMI and improve predictions?**\n",
    "\n",
    "## Approach\n",
    "\n",
    "### Naive Compositional Model\n",
    "$$P(C \\to P) = \\sum_{g} P(C \\to g) \\times P(g \\to P)$$\n",
    "\n",
    "Assumes independence regardless of degrees.\n",
    "\n",
    "### Degree-Aware Compositional Model\n",
    "$$P(C \\to P | \\text{deg}(C)=u, \\text{deg}(P)=v) = \\sum_{g: \\text{deg}(g)=w} P(C \\to g | u, w) \\times P(g \\to P | w, v)$$\n",
    "\n",
    "Stratifies by node degrees before applying compositional assumptions.\n",
    "\n",
    "## Key Hypothesis from Notebook 11\n",
    "\n",
    "Since Hetionet and null networks have identical PMI distributions (p=0.715), the conditional structure is **degree-driven**, not biology-driven. Therefore:\n",
    "\n",
    "✓ Degree-aware models should improve fit in **both** Hetionet and null networks  \n",
    "✓ Improvement should be **similar** in magnitude  \n",
    "✓ Remaining residuals may reflect biological dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "repo_dir = Path.cwd().parent\n",
    "src_dir = repo_dir / 'src'\n",
    "data_dir = repo_dir / 'data'\n",
    "results_dir = repo_dir / 'results' / 'degree_aware_compositionality'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.append(str(src_dir))\n",
    "\n",
    "print(f\"Repository: {repo_dir}\")\n",
    "print(f\"Results: {results_dir}\")\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metapath: CbGpPW (same as notebook 11)\n",
    "metapath = ['CbG', 'GpPW']\n",
    "metapath_name = 'CbGpPW'\n",
    "\n",
    "# Permutations to analyze\n",
    "PERMUTATION_IDS = [1, 2, 3, 4, 5]  # First 5 null networks\n",
    "HETIONET_ID = 0  # Real network\n",
    "\n",
    "# Degree bins (same as notebook 11)\n",
    "DEGREE_BINS = [0, 5, 20, 100, np.inf]\n",
    "DEGREE_LABELS = ['Very Low (0-5)', 'Low (5-20)', 'Medium (20-100)', 'High (>100)']\n",
    "\n",
    "print(f\"Testing metapath: {metapath_name}\")\n",
    "print(f\"  Edge 1: {metapath[0]} (Compound → Gene)\")\n",
    "print(f\"  Edge 2: {metapath[1]} (Gene → Pathway)\")\n",
    "print(f\"\\nAnalyzing Hetionet ({HETIONET_ID:03d}) + {len(PERMUTATION_IDS)} permutations\")\n",
    "print(f\"Degree bins: {DEGREE_LABELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edge_matrix(edge_type: str, perm_id: int = 0) -> sp.csr_matrix:\n",
    "    \"\"\"Load edge matrix for given edge type and permutation.\"\"\"\n",
    "    edge_file = data_dir / 'permutations' / f'{perm_id:03d}.hetmat' / 'edges' / f'{edge_type}.sparse.npz'\n",
    "    return sp.load_npz(edge_file)\n",
    "\n",
    "def analytical_prior(u: float, v: float, m: float) -> float:\n",
    "    \"\"\"Current analytical formula for edge probability.\"\"\"\n",
    "    uv = u * v\n",
    "    denominator = np.sqrt(uv**2 + (m - u - v + 1)**2)\n",
    "    return uv / denominator if denominator > 0 else 0.0\n",
    "\n",
    "def assign_degree_bin(degree: int, bins=DEGREE_BINS) -> int:\n",
    "    \"\"\"Assign degree to bin index.\"\"\"\n",
    "    for i, threshold in enumerate(bins[1:]):\n",
    "        if degree < threshold:\n",
    "            return i\n",
    "    return len(bins) - 2\n",
    "\n",
    "def compute_observed_metapath_frequencies(edge1: sp.csr_matrix, edge2: sp.csr_matrix) -> dict:\n",
    "    \"\"\"Compute observed metapath frequencies.\"\"\"\n",
    "    # Filter zero-degree nodes\n",
    "    compound_degrees = np.array(edge1.sum(axis=1)).flatten()\n",
    "    pathway_degrees = np.array(edge2.sum(axis=0)).flatten()\n",
    "    \n",
    "    compound_nonzero = np.where(compound_degrees > 0)[0]\n",
    "    pathway_nonzero = np.where(pathway_degrees > 0)[0]\n",
    "    \n",
    "    edge1_filt = edge1[compound_nonzero, :]\n",
    "    edge2_filt = edge2[:, pathway_nonzero]\n",
    "    \n",
    "    # Compute metapath matrix\n",
    "    metapath_matrix = edge1_filt @ edge2_filt\n",
    "    \n",
    "    # Compute observed frequencies\n",
    "    observed_freq = {}\n",
    "    for i, j in zip(*metapath_matrix.nonzero()):\n",
    "        compound_genes = set(edge1_filt.getrow(i).nonzero()[1])\n",
    "        pathway_genes = set(edge2_filt.getcol(j).nonzero()[0])\n",
    "        shared_genes = compound_genes & pathway_genes\n",
    "        n_paths = len(shared_genes)\n",
    "        n_possible = len(compound_genes)\n",
    "        if n_possible > 0:\n",
    "            observed_freq[(compound_nonzero[i], pathway_nonzero[j])] = n_paths / n_possible\n",
    "    \n",
    "    return observed_freq, edge1_filt, edge2_filt, compound_nonzero, pathway_nonzero\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Naive Compositional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_naive_compositional_model(edge1: sp.csr_matrix, edge2: sp.csr_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    Compute naive compositional predictions.\n",
    "    P(C→P) = sum_g P(C→g) × P(g→P)\n",
    "    \"\"\"\n",
    "    # Get degrees\n",
    "    compound_degrees = np.array(edge1.sum(axis=1)).flatten()\n",
    "    pathway_degrees = np.array(edge2.sum(axis=0)).flatten()\n",
    "    gene_degrees_1 = np.array(edge1.sum(axis=0)).flatten()\n",
    "    gene_degrees_2 = np.array(edge2.sum(axis=1)).flatten()\n",
    "    \n",
    "    m1 = edge1.nnz\n",
    "    m2 = edge2.nnz\n",
    "    \n",
    "    # Compute edge priors\n",
    "    edge1_priors = {}\n",
    "    for i, j in zip(*edge1.nonzero()):\n",
    "        u, v = compound_degrees[i], gene_degrees_1[j]\n",
    "        if u > 0 and v > 0:\n",
    "            edge1_priors[(i, j)] = analytical_prior(u, v, m1)\n",
    "    \n",
    "    edge2_priors = {}\n",
    "    for i, j in zip(*edge2.nonzero()):\n",
    "        u, v = gene_degrees_2[i], pathway_degrees[j]\n",
    "        if u > 0 and v > 0:\n",
    "            edge2_priors[(i, j)] = analytical_prior(u, v, m2)\n",
    "    \n",
    "    # Compute compositional probabilities\n",
    "    compositional_prob = {}\n",
    "    n_compounds = edge1.shape[0]\n",
    "    n_pathways = edge2.shape[1]\n",
    "    \n",
    "    for i in range(n_compounds):\n",
    "        if compound_degrees[i] == 0:\n",
    "            continue\n",
    "        compound_genes = edge1.getrow(i).nonzero()[1]\n",
    "        \n",
    "        for j in range(n_pathways):\n",
    "            if pathway_degrees[j] == 0:\n",
    "                continue\n",
    "            pathway_genes = edge2.getcol(j).nonzero()[0]\n",
    "            \n",
    "            total_prob = 0.0\n",
    "            for gene in set(compound_genes) & set(pathway_genes):\n",
    "                p1 = edge1_priors.get((i, gene), 0.0)\n",
    "                p2 = edge2_priors.get((gene, j), 0.0)\n",
    "                total_prob += p1 * p2\n",
    "            \n",
    "            if total_prob > 0:\n",
    "                compositional_prob[(i, j)] = total_prob\n",
    "    \n",
    "    return compositional_prob\n",
    "\n",
    "print(\"Naive compositional model function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Degree-Aware Compositional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_degree_aware_compositional_model(edge1: sp.csr_matrix, edge2: sp.csr_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    Compute degree-aware compositional predictions.\n",
    "    \n",
    "    Key difference from naive model:\n",
    "    - Edge priors are computed WITHIN degree bins\n",
    "    - Each bin has its own normalization (total edges in that bin)\n",
    "    \"\"\"\n",
    "    # Get degrees\n",
    "    compound_degrees = np.array(edge1.sum(axis=1)).flatten()\n",
    "    pathway_degrees = np.array(edge2.sum(axis=0)).flatten()\n",
    "    gene_degrees_1 = np.array(edge1.sum(axis=0)).flatten()\n",
    "    gene_degrees_2 = np.array(edge2.sum(axis=1)).flatten()\n",
    "    \n",
    "    # Assign degree bins\n",
    "    compound_bins = np.array([assign_degree_bin(d) for d in compound_degrees])\n",
    "    pathway_bins = np.array([assign_degree_bin(d) for d in pathway_degrees])\n",
    "    gene_bins_1 = np.array([assign_degree_bin(d) for d in gene_degrees_1])\n",
    "    gene_bins_2 = np.array([assign_degree_bin(d) for d in gene_degrees_2])\n",
    "    \n",
    "    # Count edges per degree bin combination for normalization\n",
    "    edge1_counts = defaultdict(int)\n",
    "    edge2_counts = defaultdict(int)\n",
    "    \n",
    "    for i, j in zip(*edge1.nonzero()):\n",
    "        bin_key = (compound_bins[i], gene_bins_1[j])\n",
    "        edge1_counts[bin_key] += 1\n",
    "    \n",
    "    for i, j in zip(*edge2.nonzero()):\n",
    "        bin_key = (gene_bins_2[i], pathway_bins[j])\n",
    "        edge2_counts[bin_key] += 1\n",
    "    \n",
    "    # Compute degree-aware edge priors\n",
    "    edge1_priors = {}\n",
    "    for i, j in zip(*edge1.nonzero()):\n",
    "        u, v = compound_degrees[i], gene_degrees_1[j]\n",
    "        bin_key = (compound_bins[i], gene_bins_1[j])\n",
    "        m_bin = edge1_counts[bin_key]\n",
    "        if u > 0 and v > 0 and m_bin > 0:\n",
    "            edge1_priors[(i, j)] = analytical_prior(u, v, m_bin)\n",
    "    \n",
    "    edge2_priors = {}\n",
    "    for i, j in zip(*edge2.nonzero()):\n",
    "        u, v = gene_degrees_2[i], pathway_degrees[j]\n",
    "        bin_key = (gene_bins_2[i], pathway_bins[j])\n",
    "        m_bin = edge2_counts[bin_key]\n",
    "        if u > 0 and v > 0 and m_bin > 0:\n",
    "            edge2_priors[(i, j)] = analytical_prior(u, v, m_bin)\n",
    "    \n",
    "    # Compute compositional probabilities (same as naive)\n",
    "    compositional_prob = {}\n",
    "    n_compounds = edge1.shape[0]\n",
    "    n_pathways = edge2.shape[1]\n",
    "    \n",
    "    for i in range(n_compounds):\n",
    "        if compound_degrees[i] == 0:\n",
    "            continue\n",
    "        compound_genes = edge1.getrow(i).nonzero()[1]\n",
    "        \n",
    "        for j in range(n_pathways):\n",
    "            if pathway_degrees[j] == 0:\n",
    "                continue\n",
    "            pathway_genes = edge2.getcol(j).nonzero()[0]\n",
    "            \n",
    "            total_prob = 0.0\n",
    "            for gene in set(compound_genes) & set(pathway_genes):\n",
    "                p1 = edge1_priors.get((i, gene), 0.0)\n",
    "                p2 = edge2_priors.get((gene, j), 0.0)\n",
    "                total_prob += p1 * p2\n",
    "            \n",
    "            if total_prob > 0:\n",
    "                compositional_prob[(i, j)] = total_prob\n",
    "    \n",
    "    return compositional_prob\n",
    "\n",
    "print(\"Degree-aware compositional model function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Hetionet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing Hetionet...\\n\")\n",
    "\n",
    "# Load edges\n",
    "edge1_het = load_edge_matrix(metapath[0], HETIONET_ID)\n",
    "edge2_het = load_edge_matrix(metapath[1], HETIONET_ID)\n",
    "\n",
    "print(f\"Edge matrices loaded:\")\n",
    "print(f\"  {metapath[0]}: {edge1_het.shape}, {edge1_het.nnz} edges\")\n",
    "print(f\"  {metapath[1]}: {edge2_het.shape}, {edge2_het.nnz} edges\")\n",
    "\n",
    "# Compute observed frequencies\n",
    "print(\"\\nComputing observed metapath frequencies...\")\n",
    "observed_freq, _, _, _, _ = compute_observed_metapath_frequencies(edge1_het, edge2_het)\n",
    "print(f\"  Found {len(observed_freq)} metapath pairs\")\n",
    "\n",
    "# Compute naive compositional predictions\n",
    "print(\"\\nComputing naive compositional model...\")\n",
    "naive_pred = compute_naive_compositional_model(edge1_het, edge2_het)\n",
    "print(f\"  Generated {len(naive_pred)} predictions\")\n",
    "\n",
    "# Compute degree-aware compositional predictions\n",
    "print(\"\\nComputing degree-aware compositional model...\")\n",
    "degree_aware_pred = compute_degree_aware_compositional_model(edge1_het, edge2_het)\n",
    "print(f\"  Generated {len(degree_aware_pred)} predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common pairs for fair comparison\n",
    "common_pairs = set(observed_freq.keys()) & set(naive_pred.keys()) & set(degree_aware_pred.keys())\n",
    "print(f\"Common pairs across all three: {len(common_pairs)}\")\n",
    "\n",
    "# Extract values for common pairs\n",
    "y_true = np.array([observed_freq[pair] for pair in common_pairs])\n",
    "y_naive = np.array([naive_pred[pair] for pair in common_pairs])\n",
    "y_degree_aware = np.array([degree_aware_pred[pair] for pair in common_pairs])\n",
    "\n",
    "# Compute metrics\n",
    "naive_corr = pearsonr(y_true, y_naive)[0]\n",
    "degree_aware_corr = pearsonr(y_true, y_degree_aware)[0]\n",
    "\n",
    "naive_rmse = np.sqrt(mean_squared_error(y_true, y_naive))\n",
    "degree_aware_rmse = np.sqrt(mean_squared_error(y_true, y_degree_aware))\n",
    "\n",
    "naive_mae = mean_absolute_error(y_true, y_naive)\n",
    "degree_aware_mae = mean_absolute_error(y_true, y_degree_aware)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON - HETIONET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nNaive Compositional Model:\")\n",
    "print(f\"  Correlation: {naive_corr:.4f}\")\n",
    "print(f\"  RMSE:        {naive_rmse:.4f}\")\n",
    "print(f\"  MAE:         {naive_mae:.4f}\")\n",
    "\n",
    "print(f\"\\nDegree-Aware Compositional Model:\")\n",
    "print(f\"  Correlation: {degree_aware_corr:.4f}\")\n",
    "print(f\"  RMSE:        {degree_aware_rmse:.4f}\")\n",
    "print(f\"  MAE:         {degree_aware_mae:.4f}\")\n",
    "\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"  Δ Correlation: {degree_aware_corr - naive_corr:+.4f} ({(degree_aware_corr - naive_corr) / abs(naive_corr) * 100:+.1f}%)\")\n",
    "print(f\"  Δ RMSE:        {degree_aware_rmse - naive_rmse:+.4f} ({(degree_aware_rmse - naive_rmse) / naive_rmse * 100:+.1f}%)\")\n",
    "print(f\"  Δ MAE:         {degree_aware_mae - naive_mae:+.4f} ({(degree_aware_mae - naive_mae) / naive_mae * 100:+.1f}%)\")\n",
    "\n",
    "if degree_aware_corr > naive_corr:\n",
    "    print(f\"\\n✓ DEGREE-AWARE MODEL IMPROVES FIT\")\n",
    "else:\n",
    "    print(f\"\\n✗ No improvement from degree stratification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PMI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PMI for both models\n",
    "def compute_pmi(observed, predicted):\n",
    "    \"\"\"Compute PMI = log2(observed / predicted)\"\"\"\n",
    "    pmi = []\n",
    "    for obs, pred in zip(observed, predicted):\n",
    "        if obs > 0 and pred > 0:\n",
    "            pmi.append(np.log2(obs / pred))\n",
    "    return np.array(pmi)\n",
    "\n",
    "pmi_naive = compute_pmi(y_true, y_naive)\n",
    "pmi_degree_aware = compute_pmi(y_true, y_degree_aware)\n",
    "\n",
    "print(\"\\nPMI Analysis:\")\n",
    "print(f\"\\nNaive Model:\")\n",
    "print(f\"  Mean PMI:   {pmi_naive.mean():.4f}\")\n",
    "print(f\"  Median PMI: {np.median(pmi_naive):.4f}\")\n",
    "print(f\"  Std PMI:    {pmi_naive.std():.4f}\")\n",
    "\n",
    "print(f\"\\nDegree-Aware Model:\")\n",
    "print(f\"  Mean PMI:   {pmi_degree_aware.mean():.4f}\")\n",
    "print(f\"  Median PMI: {np.median(pmi_degree_aware):.4f}\")\n",
    "print(f\"  Std PMI:    {pmi_degree_aware.std():.4f}\")\n",
    "\n",
    "print(f\"\\nPMI Reduction:\")\n",
    "print(f\"  Δ Mean PMI: {pmi_degree_aware.mean() - pmi_naive.mean():.4f}\")\n",
    "\n",
    "if abs(pmi_degree_aware.mean()) < abs(pmi_naive.mean()):\n",
    "    print(f\"\\n✓ DEGREE-AWARE MODEL REDUCES PMI (closer to 0 = better compositional fit)\")\n",
    "else:\n",
    "    print(f\"\\n→ No PMI reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stratified Analysis by Degree Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get degrees for stratification\n",
    "compound_degrees = np.array(edge1_het.sum(axis=1)).flatten()\n",
    "pathway_degrees = np.array(edge2_het.sum(axis=0)).flatten()\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'compound_idx': [pair[0] for pair in common_pairs],\n",
    "    'pathway_idx': [pair[1] for pair in common_pairs],\n",
    "    'observed': y_true,\n",
    "    'naive_pred': y_naive,\n",
    "    'degree_aware_pred': y_degree_aware\n",
    "})\n",
    "\n",
    "results_df['compound_degree'] = results_df['compound_idx'].map(lambda i: compound_degrees[i])\n",
    "results_df['pathway_degree'] = results_df['pathway_idx'].map(lambda i: pathway_degrees[i])\n",
    "\n",
    "results_df['compound_bin'] = pd.cut(results_df['compound_degree'], bins=DEGREE_BINS, labels=DEGREE_LABELS)\n",
    "results_df['pathway_bin'] = pd.cut(results_df['pathway_degree'], bins=DEGREE_BINS, labels=DEGREE_LABELS)\n",
    "\n",
    "results_df['pmi_naive'] = np.log2(results_df['observed'] / results_df['naive_pred'])\n",
    "results_df['pmi_degree_aware'] = np.log2(results_df['observed'] / results_df['degree_aware_pred'])\n",
    "\n",
    "print(\"\\nPerformance by Compound Degree Bin:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for bin_label in DEGREE_LABELS:\n",
    "    subset = results_df[results_df['compound_bin'] == bin_label]\n",
    "    if len(subset) > 1:\n",
    "        naive_corr_bin = pearsonr(subset['observed'], subset['naive_pred'])[0]\n",
    "        da_corr_bin = pearsonr(subset['observed'], subset['degree_aware_pred'])[0]\n",
    "        \n",
    "        print(f\"\\n{bin_label} (n={len(subset)}):\")\n",
    "        print(f\"  Naive correlation:        {naive_corr_bin:.4f}\")\n",
    "        print(f\"  Degree-aware correlation: {da_corr_bin:.4f}\")\n",
    "        print(f\"  Improvement:              {da_corr_bin - naive_corr_bin:+.4f}\")\n",
    "        print(f\"  Mean PMI (naive):         {subset['pmi_naive'].mean():.4f}\")\n",
    "        print(f\"  Mean PMI (degree-aware):  {subset['pmi_degree_aware'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Null Network Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAnalyzing {len(PERMUTATION_IDS)} null networks...\\n\")\n",
    "\n",
    "null_results = []\n",
    "\n",
    "for perm_id in tqdm(PERMUTATION_IDS, desc=\"Processing permutations\"):\n",
    "    # Load edges\n",
    "    edge1_perm = load_edge_matrix(metapath[0], perm_id)\n",
    "    edge2_perm = load_edge_matrix(metapath[1], perm_id)\n",
    "    \n",
    "    # Compute observed\n",
    "    obs_freq, _, _, _, _ = compute_observed_metapath_frequencies(edge1_perm, edge2_perm)\n",
    "    \n",
    "    # Compute predictions\n",
    "    naive_perm = compute_naive_compositional_model(edge1_perm, edge2_perm)\n",
    "    da_perm = compute_degree_aware_compositional_model(edge1_perm, edge2_perm)\n",
    "    \n",
    "    # Common pairs\n",
    "    common = set(obs_freq.keys()) & set(naive_perm.keys()) & set(da_perm.keys())\n",
    "    \n",
    "    if len(common) > 1:\n",
    "        y_obs = np.array([obs_freq[p] for p in common])\n",
    "        y_naive_p = np.array([naive_perm[p] for p in common])\n",
    "        y_da_p = np.array([da_perm[p] for p in common])\n",
    "        \n",
    "        naive_corr_p = pearsonr(y_obs, y_naive_p)[0]\n",
    "        da_corr_p = pearsonr(y_obs, y_da_p)[0]\n",
    "        \n",
    "        null_results.append({\n",
    "            'perm_id': perm_id,\n",
    "            'naive_corr': naive_corr_p,\n",
    "            'degree_aware_corr': da_corr_p,\n",
    "            'improvement': da_corr_p - naive_corr_p,\n",
    "            'n_pairs': len(common)\n",
    "        })\n",
    "\n",
    "null_df = pd.DataFrame(null_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NULL NETWORK RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nNull Networks (n={len(null_df)}):\")\n",
    "print(f\"  Naive correlation:        {null_df['naive_corr'].mean():.4f} ± {null_df['naive_corr'].std():.4f}\")\n",
    "print(f\"  Degree-aware correlation: {null_df['degree_aware_corr'].mean():.4f} ± {null_df['degree_aware_corr'].std():.4f}\")\n",
    "print(f\"  Mean improvement:         {null_df['improvement'].mean():+.4f} ± {null_df['improvement'].std():.4f}\")\n",
    "\n",
    "print(f\"\\nHetionet vs Null:\")\n",
    "het_improvement = degree_aware_corr - naive_corr\n",
    "null_improvement = null_df['improvement'].mean()\n",
    "print(f\"  Hetionet improvement:     {het_improvement:+.4f}\")\n",
    "print(f\"  Null improvement:         {null_improvement:+.4f}\")\n",
    "print(f\"  Difference:               {het_improvement - null_improvement:+.4f}\")\n",
    "\n",
    "if abs(het_improvement - null_improvement) < 0.01:\n",
    "    print(f\"\\n✓ SIMILAR IMPROVEMENT IN HETIONET AND NULL\")\n",
    "    print(f\"  → Confirms degree structure is main driver of conditional dependencies\")\n",
    "    print(f\"  → Biology adds minimal signal beyond degrees\")\n",
    "else:\n",
    "    print(f\"\\n→ DIFFERENT IMPROVEMENT PATTERNS\")\n",
    "    print(f\"  → May indicate biological signal beyond degree structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 13))\n",
    "\n",
    "# 1. Scatter: Observed vs Naive\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(y_true, y_naive, alpha=0.5, s=10, edgecolors='none')\n",
    "ax.plot([0, 1], [0, 1], 'r--', alpha=0.8, linewidth=2)\n",
    "ax.set_xlabel('Observed Frequency', fontsize=12)\n",
    "ax.set_ylabel('Naive Compositional Prediction', fontsize=12)\n",
    "ax.set_title(f'Naive Model (r={naive_corr:.3f})', fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, max(y_naive.max(), 1))\n",
    "\n",
    "# 2. Scatter: Observed vs Degree-Aware\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(y_true, y_degree_aware, alpha=0.5, s=10, edgecolors='none', color='green')\n",
    "ax.plot([0, 1], [0, 1], 'r--', alpha=0.8, linewidth=2)\n",
    "ax.set_xlabel('Observed Frequency', fontsize=12)\n",
    "ax.set_ylabel('Degree-Aware Prediction', fontsize=12)\n",
    "ax.set_title(f'Degree-Aware Model (r={degree_aware_corr:.3f})', fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, max(y_degree_aware.max(), 1))\n",
    "\n",
    "# 3. PMI distributions\n",
    "ax = axes[0, 2]\n",
    "ax.hist(pmi_naive, bins=50, alpha=0.6, label='Naive', edgecolor='black')\n",
    "ax.hist(pmi_degree_aware, bins=50, alpha=0.6, label='Degree-Aware', edgecolor='black', color='green')\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Perfect Fit (PMI=0)')\n",
    "ax.set_xlabel('PMI', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('PMI Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 4. Correlation by compound degree\n",
    "ax = axes[1, 0]\n",
    "corr_by_compound = []\n",
    "for bin_label in DEGREE_LABELS:\n",
    "    subset = results_df[results_df['compound_bin'] == bin_label]\n",
    "    if len(subset) > 1:\n",
    "        naive_c = pearsonr(subset['observed'], subset['naive_pred'])[0]\n",
    "        da_c = pearsonr(subset['observed'], subset['degree_aware_pred'])[0]\n",
    "        corr_by_compound.append({'bin': bin_label, 'naive': naive_c, 'degree_aware': da_c})\n",
    "\n",
    "if corr_by_compound:\n",
    "    corr_compound_df = pd.DataFrame(corr_by_compound)\n",
    "    x = np.arange(len(corr_compound_df))\n",
    "    width = 0.35\n",
    "    ax.bar(x - width/2, corr_compound_df['naive'], width, label='Naive', alpha=0.7)\n",
    "    ax.bar(x + width/2, corr_compound_df['degree_aware'], width, label='Degree-Aware', alpha=0.7, color='green')\n",
    "    ax.set_xlabel('Compound Degree Bin', fontsize=12)\n",
    "    ax.set_ylabel('Correlation', fontsize=12)\n",
    "    ax.set_title('Correlation by Compound Degree', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(corr_compound_df['bin'], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# 5. Null network improvement distribution\n",
    "ax = axes[1, 1]\n",
    "ax.hist(null_df['improvement'], bins=15, alpha=0.7, edgecolor='black', color='blue')\n",
    "ax.axvline(het_improvement, color='red', linestyle='--', linewidth=3, label=f'Hetionet ({het_improvement:+.3f})')\n",
    "ax.axvline(null_improvement, color='blue', linestyle='--', linewidth=2, label=f'Null mean ({null_improvement:+.3f})')\n",
    "ax.set_xlabel('Improvement in Correlation', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('Degree-Aware Improvement: Hetionet vs Null', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 6. Residual comparison\n",
    "ax = axes[1, 2]\n",
    "residual_naive = y_true - y_naive\n",
    "residual_da = y_true - y_degree_aware\n",
    "ax.scatter(residual_naive, residual_da, alpha=0.5, s=10, edgecolors='none')\n",
    "ax.plot([residual_naive.min(), residual_naive.max()], [residual_naive.min(), residual_naive.max()], 'r--', alpha=0.8)\n",
    "ax.set_xlabel('Naive Residuals', fontsize=12)\n",
    "ax.set_ylabel('Degree-Aware Residuals', fontsize=12)\n",
    "ax.set_title(f'Residual Comparison', fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "ax.axvline(0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / f'{metapath_name}_degree_aware_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVisualization saved to: {results_dir / f'{metapath_name}_degree_aware_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Hetionet results\n",
    "results_df.to_csv(results_dir / f'{metapath_name}_hetionet_results.csv', index=False)\n",
    "\n",
    "# Save null results\n",
    "null_df.to_csv(results_dir / f'{metapath_name}_null_results.csv', index=False)\n",
    "\n",
    "# Save summary\n",
    "summary = {\n",
    "    'metapath': metapath_name,\n",
    "    'hetionet_naive_corr': naive_corr,\n",
    "    'hetionet_degree_aware_corr': degree_aware_corr,\n",
    "    'hetionet_improvement': het_improvement,\n",
    "    'hetionet_naive_rmse': naive_rmse,\n",
    "    'hetionet_degree_aware_rmse': degree_aware_rmse,\n",
    "    'hetionet_naive_pmi_mean': pmi_naive.mean(),\n",
    "    'hetionet_degree_aware_pmi_mean': pmi_degree_aware.mean(),\n",
    "    'null_naive_corr_mean': null_df['naive_corr'].mean(),\n",
    "    'null_degree_aware_corr_mean': null_df['degree_aware_corr'].mean(),\n",
    "    'null_improvement_mean': null_improvement,\n",
    "    'n_hetionet_pairs': len(common_pairs),\n",
    "    'n_null_networks': len(null_df)\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(results_dir / f'{metapath_name}_summary.csv', index=False)\n",
    "\n",
    "print(f\"\\nResults saved to:\")\n",
    "print(f\"  - {results_dir / f'{metapath_name}_hetionet_results.csv'}\")\n",
    "print(f\"  - {results_dir / f'{metapath_name}_null_results.csv'}\")\n",
    "print(f\"  - {results_dir / f'{metapath_name}_summary.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSIONS: DEGREE-AWARE COMPOSITIONAL MODELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. MODEL PERFORMANCE:\")\n",
    "print(f\"   Naive compositional:      r = {naive_corr:.4f}\")\n",
    "print(f\"   Degree-aware:             r = {degree_aware_corr:.4f}\")\n",
    "print(f\"   Improvement:              Δr = {het_improvement:+.4f} ({het_improvement / abs(naive_corr) * 100:+.1f}%)\")\n",
    "\n",
    "if het_improvement > 0.01:\n",
    "    print(f\"\\n   ✓ DEGREE-AWARE MODEL SIGNIFICANTLY IMPROVES FIT\")\n",
    "elif het_improvement > 0:\n",
    "    print(f\"\\n   → Modest improvement from degree stratification\")\n",
    "else:\n",
    "    print(f\"\\n   ✗ No improvement or degradation\")\n",
    "\n",
    "print(f\"\\n2. PMI REDUCTION:\")\n",
    "print(f\"   Naive PMI:                {pmi_naive.mean():.4f}\")\n",
    "print(f\"   Degree-aware PMI:         {pmi_degree_aware.mean():.4f}\")\n",
    "print(f\"   Reduction:                {pmi_naive.mean() - pmi_degree_aware.mean():.4f}\")\n",
    "\n",
    "if abs(pmi_degree_aware.mean()) < abs(pmi_naive.mean()):\n",
    "    print(f\"\\n   ✓ PMI closer to 0 → better compositional fit\")\n",
    "\n",
    "print(f\"\\n3. HETIONET VS NULL:\")\n",
    "print(f\"   Hetionet improvement:     {het_improvement:+.4f}\")\n",
    "print(f\"   Null improvement (mean):  {null_improvement:+.4f}\")\n",
    "print(f\"   Difference:               {abs(het_improvement - null_improvement):.4f}\")\n",
    "\n",
    "if abs(het_improvement - null_improvement) < 0.01:\n",
    "    print(f\"\\n   ✓ SIMILAR IMPROVEMENT (difference < 0.01)\")\n",
    "    print(f\"     → Degree structure is primary driver\")\n",
    "    print(f\"     → Biological dependencies are minimal\")\n",
    "else:\n",
    "    print(f\"\\n   → DIFFERENT IMPROVEMENT PATTERNS\")\n",
    "    print(f\"     → Potential biological signal beyond degrees\")\n",
    "\n",
    "print(f\"\\n4. RECOMMENDATIONS:\")\n",
    "\n",
    "if het_improvement > 0.05 and abs(het_improvement - null_improvement) < 0.02:\n",
    "    print(f\"   → USE DEGREE-AWARE COMPOSITIONAL MODELS\")\n",
    "    print(f\"   → Substantial improvement from degree stratification\")\n",
    "    print(f\"   → Apply to both Hetionet and null networks\")\n",
    "    print(f\"   → Stratify by {len(DEGREE_BINS)-1} degree bins: {DEGREE_LABELS}\")\n",
    "elif het_improvement > 0:\n",
    "    print(f\"   → DEGREE-AWARE MODELS PROVIDE MODEST BENEFIT\")\n",
    "    print(f\"   → Consider simpler degree-correction methods\")\n",
    "    print(f\"   → May not be worth added complexity\")\n",
    "else:\n",
    "    print(f\"   → DEGREE STRATIFICATION NOT HELPFUL\")\n",
    "    print(f\"   → Use naive compositional or ML approaches\")\n",
    "\n",
    "if abs(het_improvement - null_improvement) > 0.02:\n",
    "    print(f\"\\n   → BIOLOGICAL SIGNAL DETECTED\")\n",
    "    print(f\"   → Consider hybrid: degree-aware + biological corrections\")\n",
    "    print(f\"   → ML models may capture additional structure\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
